# ğŸ¤– AIå¼€å‘æŒ‡å— - Vibe Photosæ™ºèƒ½ç…§ç‰‡ç®¡ç†ç³»ç»Ÿ

> æœ¬æ–‡æ¡£ä¸“ä¸ºCoding AIç¼–å†™ï¼Œæä¾›ç»“æ„åŒ–çš„ä»»åŠ¡æŒ‡ä»¤å’Œå®ç°è§„èŒƒ

## ğŸ“‹ é¡¹ç›®æ¦‚è¿°

### ç³»ç»Ÿå®šä¹‰
- **åç§°**: Vibe Photos
- **ç±»å‹**: AIæ™ºèƒ½ç…§ç‰‡ç®¡ç†ç³»ç»Ÿ
- **ç›®æ ‡ç”¨æˆ·**: è‡ªåª’ä½“åˆ›ä½œè€…ï¼ˆäº§å“è¯„æµ‹ã€ç¾é£Ÿæ¨èã€æŠ€æœ¯æ•™ç¨‹ï¼‰
- **æ ¸å¿ƒä»·å€¼**: ä»æµ·é‡ç…§ç‰‡ä¸­å¿«é€Ÿæ‰¾åˆ°æ‰€éœ€ç´ æ

### æŠ€æœ¯çº¦æŸ
- **Pythonç‰ˆæœ¬**: 3.12ï¼ˆå›ºå®šï¼‰
- **åŒ…ç®¡ç†å™¨**: uvï¼ˆå¿…é¡»ä½¿ç”¨ï¼Œç¦æ­¢pip/poetry/condaï¼‰
- **å¼€å‘æ–¹å¼**: å‡½æ•°å¼ç¼–ç¨‹ä¼˜å…ˆï¼Œé¿å…ä¸å¿…è¦çš„ç±»
- **APIæ¡†æ¶**: FastAPIï¼ˆå¼‚æ­¥ä¼˜å…ˆï¼‰
- **é”™è¯¯å¤„ç†**: æ—©æœŸè¿”å›ï¼Œguard clauses

## ğŸ¯ æ ¸å¿ƒåŠŸèƒ½éœ€æ±‚

### å¿…é¡»å®ç°çš„åŠŸèƒ½
1. **å›¾åƒè¯†åˆ«**: è¯†åˆ«ç”µå­äº§å“ã€ç¾é£Ÿã€æ–‡æ¡£ã€äººç‰©ã€é£æ™¯
2. **æ™ºèƒ½æœç´¢**: æ”¯æŒè‡ªç„¶è¯­è¨€æŸ¥è¯¢ï¼Œå¦‚"æœ€è¿‘æ‹çš„iPhone"
3. **æ‰¹é‡å¤„ç†**: ä¸€æ¬¡å¤„ç†1000+å¼ ç…§ç‰‡ï¼Œé€Ÿåº¦>10å¼ /ç§’
4. **OCRæå–**: è¯†åˆ«å›¾ç‰‡ä¸­çš„æ–‡å­—ï¼ˆä¸­è‹±æ–‡ï¼‰
5. **ç›¸ä¼¼åˆ†ç»„**: è‡ªåŠ¨å°†ç›¸ä¼¼ç…§ç‰‡åˆ†ç»„
6. **å¢é‡æ›´æ–°**: åªå¤„ç†æ–°å¢ç…§ç‰‡

### ä¸å®ç°çš„åŠŸèƒ½
- âŒ å›¾åƒç¼–è¾‘
- âŒ äº‘ç«¯å­˜å‚¨
- âŒ ç¤¾äº¤åˆ†äº«
- âŒ 100%å…¨è‡ªåŠ¨åŒ–ï¼ˆä¿ç•™äººå·¥å¹²é¢„ï¼‰

## ğŸ—ï¸ é¡¹ç›®ç»“æ„è§„èŒƒ

```
vibe_photos_v3/
â”œâ”€â”€ src/                           # æºä»£ç ç›®å½•
â”‚   â”œâ”€â”€ core/                      # æ ¸å¿ƒåŠŸèƒ½æ¨¡å—
â”‚   â”‚   â”œâ”€â”€ detector.py            # å›¾åƒæ£€æµ‹å™¨
â”‚   â”‚   â”œâ”€â”€ processor.py           # å›¾åƒå¤„ç†å™¨
â”‚   â”‚   â”œâ”€â”€ searcher.py            # æœç´¢å¼•æ“
â”‚   â”‚   â””â”€â”€ database.py            # æ•°æ®åº“æ“ä½œ
â”‚   â”œâ”€â”€ models/                    # AIæ¨¡å‹å°è£…
â”‚   â”‚   â”œâ”€â”€ siglip_model.py        # SigLIPæ¨¡å‹
â”‚   â”‚   â”œâ”€â”€ blip_model.py          # BLIPæ¨¡å‹
â”‚   â”‚   â””â”€â”€ ocr_model.py           # OCRæ¨¡å‹
â”‚   â”œâ”€â”€ api/                       # APIæ¥å£
â”‚   â”‚   â”œâ”€â”€ main.py                # FastAPIä¸»åº”ç”¨
â”‚   â”‚   â”œâ”€â”€ routes/                # è·¯ç”±å®šä¹‰
â”‚   â”‚   â”‚   â”œâ”€â”€ import_routes.py   # å¯¼å…¥æ¥å£
â”‚   â”‚   â”‚   â”œâ”€â”€ search_routes.py   # æœç´¢æ¥å£
â”‚   â”‚   â”‚   â””â”€â”€ annotation_routes.py # æ ‡æ³¨æ¥å£
â”‚   â”‚   â””â”€â”€ schemas.py             # Pydanticæ¨¡å‹
â”‚   â”œâ”€â”€ utils/                     # å·¥å…·å‡½æ•°
â”‚   â”‚   â”œâ”€â”€ image_utils.py         # å›¾åƒå¤„ç†å·¥å…·
â”‚   â”‚   â”œâ”€â”€ cache_manager.py       # ç¼“å­˜ç®¡ç†
â”‚   â”‚   â””â”€â”€ logger.py              # æ—¥å¿—é…ç½®
â”‚   â””â”€â”€ cli.py                     # å‘½ä»¤è¡Œæ¥å£
â”œâ”€â”€ tests/                         # æµ‹è¯•ç›®å½•
â”‚   â”œâ”€â”€ test_detector.py
â”‚   â”œâ”€â”€ test_search.py
â”‚   â””â”€â”€ fixtures/                  # æµ‹è¯•æ•°æ®
â”œâ”€â”€ config/                        # é…ç½®æ–‡ä»¶
â”‚   â””â”€â”€ settings.yaml
â”œâ”€â”€ data/                          # æ•°æ®å­˜å‚¨
â”œâ”€â”€ cache/                         # ç¼“å­˜ç›®å½•
â”œâ”€â”€ models/                        # æ¨¡å‹æ–‡ä»¶
â””â”€â”€ pyproject.toml                 # é¡¹ç›®é…ç½®
```

## ğŸ“ Phase 1: MVPå®ç°ï¼ˆ2å‘¨ï¼‰

### ä»»åŠ¡1.1: ç¯å¢ƒåˆå§‹åŒ–
```bash
# æ‰§è¡Œä»¥ä¸‹å‘½ä»¤åˆå§‹åŒ–é¡¹ç›®
uv init
uv add torch==2.9.1 torchvision transformers==4.57.1 pillow fastapi uvicorn typer rich
uv add paddlepaddle paddleocr sqlalchemy pydantic
```

### ä»»åŠ¡1.2: å®ç°æ ¸å¿ƒæ£€æµ‹å™¨
åˆ›å»º `src/core/detector.py`:

```python
from typing import Dict, List, Optional
from pathlib import Path
from transformers import AutoModel, AutoProcessor, BlipProcessor, BlipForConditionalGeneration
from PIL import Image
import torch

class ImageDetector:
    """å›¾åƒæ£€æµ‹å™¨ - ä½¿ç”¨SigLIP+BLIPç»„åˆ"""
    
    def __init__(self):
        # SigLIP: å¤šè¯­è¨€åˆ†ç±»
        self.siglip_processor = AutoProcessor.from_pretrained(
            "google/siglip-base-patch16-224-i18n"
        )
        self.siglip_model = AutoModel.from_pretrained(
            "google/siglip-base-patch16-224-i18n"
        )
        
        # BLIP: å›¾åƒæè¿°
        self.blip_processor = BlipProcessor.from_pretrained(
            "Salesforce/blip-image-captioning-base"
        )
        self.blip_model = BlipForConditionalGeneration.from_pretrained(
            "Salesforce/blip-image-captioning-base"
        )
    
    def detect(
        self, 
        image_path: Path,
        candidate_labels: Optional[List[str]] = None
    ) -> Dict:
        """
        æ£€æµ‹å›¾åƒå†…å®¹
        
        Args:
            image_path: å›¾åƒæ–‡ä»¶è·¯å¾„
            candidate_labels: å€™é€‰æ ‡ç­¾åˆ—è¡¨ï¼ˆæ”¯æŒä¸­æ–‡ï¼‰
            
        Returns:
            åŒ…å«åˆ†ç±»ç»“æœå’Œæè¿°çš„å­—å…¸
        """
        # æ—©æœŸè¿”å›æ¨¡å¼
        if not image_path.exists():
            return {"error": "Image file not found"}
            
        image = Image.open(image_path).convert("RGB")
        
        # é»˜è®¤æ ‡ç­¾
        if candidate_labels is None:
            candidate_labels = [
                "ç”µå­äº§å“", "iPhone", "MacBook", "ç›¸æœº",
                "ç¾é£Ÿ", "æŠ«è¨", "å’–å•¡", "è›‹ç³•",
                "æ–‡æ¡£", "æˆªå›¾", "è¯ä»¶",
                "äººç‰©", "é£æ™¯", "å»ºç­‘"
            ]
        
        # SigLIPåˆ†ç±»
        inputs = self.siglip_processor(
            text=candidate_labels, 
            images=image,
            padding=True, 
            return_tensors="pt"
        )
        
        with torch.no_grad():
            outputs = self.siglip_model(**inputs)
            logits = outputs.logits_per_image
            probs = torch.sigmoid(logits)
        
        # BLIPæè¿°
        caption_inputs = self.blip_processor(image, return_tensors="pt")
        caption_ids = self.blip_model.generate(**caption_inputs, max_length=50)
        caption = self.blip_processor.decode(caption_ids[0], skip_special_tokens=True)
        
        # æ„å»ºç»“æœ
        classifications = {
            label: float(prob) 
            for label, prob in zip(candidate_labels, probs[0])
            if prob > 0.1  # åªè¿”å›ç½®ä¿¡åº¦>10%çš„ç»“æœ
        }
        
        # æŒ‰ç½®ä¿¡åº¦æ’åº
        sorted_classifications = dict(
            sorted(classifications.items(), key=lambda x: x[1], reverse=True)
        )
        
        return {
            "image_path": str(image_path),
            "classifications": sorted_classifications,
            "top_category": list(sorted_classifications.keys())[0] if sorted_classifications else "unknown",
            "confidence": list(sorted_classifications.values())[0] if sorted_classifications else 0.0,
            "caption": caption,
            "status": "success"
        }
```

### ä»»åŠ¡1.3: å®ç°æ•°æ®åº“å±‚
åˆ›å»º `src/core/database.py`:

```python
from sqlalchemy import create_engine, Column, Integer, String, Float, DateTime, JSON, Text
from sqlalchemy.ext.declarative import declarative_base
from sqlalchemy.orm import sessionmaker
from datetime import datetime
from typing import Optional, List, Dict
import json

Base = declarative_base()

class Photo(Base):
    """ç…§ç‰‡æ•°æ®æ¨¡å‹"""
    __tablename__ = "photos"
    
    id = Column(Integer, primary_key=True)
    path = Column(String, unique=True, nullable=False)
    hash = Column(String, index=True)
    
    # å…ƒæ•°æ®
    width = Column(Integer)
    height = Column(Integer)
    size = Column(Integer)
    taken_at = Column(DateTime)
    imported_at = Column(DateTime, default=datetime.utcnow)
    
    # AIè¯†åˆ«ç»“æœ
    category = Column(String, index=True)
    confidence = Column(Float)
    classifications = Column(JSON)  # æ‰€æœ‰åˆ†ç±»ç»“æœ
    caption = Column(Text)  # BLIPç”Ÿæˆçš„æè¿°
    ocr_text = Column(Text)  # OCRæå–çš„æ–‡å­—
    
    # ç”¨æˆ·æ•°æ®
    user_label = Column(String, index=True)
    user_tags = Column(Text)  # é€—å·åˆ†éš”çš„æ ‡ç­¾
    
    # å‘é‡åµŒå…¥ï¼ˆä¸ºPhase 2é¢„ç•™ï¼‰
    embedding_json = Column(Text)  # JSONåºåˆ—åŒ–çš„å‘é‡

class DatabaseManager:
    """æ•°æ®åº“ç®¡ç†å™¨"""
    
    def __init__(self, db_path: str = "data/vibe_photos.db"):
        self.engine = create_engine(f"sqlite:///{db_path}", echo=False)
        Base.metadata.create_all(self.engine)
        self.Session = sessionmaker(bind=self.engine)
    
    def add_photo(self, photo_data: Dict) -> int:
        """æ·»åŠ ç…§ç‰‡è®°å½•"""
        session = self.Session()
        try:
            photo = Photo(**photo_data)
            session.add(photo)
            session.commit()
            return photo.id
        except Exception as e:
            session.rollback()
            raise e
        finally:
            session.close()
    
    def search_photos(
        self, 
        query: str,
        category: Optional[str] = None,
        min_confidence: float = 0.5,
        limit: int = 50
    ) -> List[Photo]:
        """æœç´¢ç…§ç‰‡"""
        session = self.Session()
        try:
            q = session.query(Photo)
            
            # æ–‡æœ¬æœç´¢
            if query:
                search_pattern = f"%{query}%"
                q = q.filter(
                    (Photo.category.like(search_pattern)) |
                    (Photo.caption.like(search_pattern)) |
                    (Photo.ocr_text.like(search_pattern)) |
                    (Photo.user_label.like(search_pattern)) |
                    (Photo.user_tags.like(search_pattern))
                )
            
            # ç±»åˆ«è¿‡æ»¤
            if category:
                q = q.filter(Photo.category == category)
            
            # ç½®ä¿¡åº¦è¿‡æ»¤
            q = q.filter(Photo.confidence >= min_confidence)
            
            # æ’åºå’Œé™åˆ¶
            q = q.order_by(Photo.confidence.desc()).limit(limit)
            
            return q.all()
        finally:
            session.close()
    
    def get_photo_by_path(self, path: str) -> Optional[Photo]:
        """æ ¹æ®è·¯å¾„è·å–ç…§ç‰‡"""
        session = self.Session()
        try:
            return session.query(Photo).filter_by(path=path).first()
        finally:
            session.close()
    
    def update_photo(self, photo_id: int, updates: Dict) -> bool:
        """æ›´æ–°ç…§ç‰‡ä¿¡æ¯"""
        session = self.Session()
        try:
            photo = session.query(Photo).filter_by(id=photo_id).first()
            if not photo:
                return False
            
            for key, value in updates.items():
                if hasattr(photo, key):
                    setattr(photo, key, value)
            
            session.commit()
            return True
        except Exception as e:
            session.rollback()
            raise e
        finally:
            session.close()
```

### ä»»åŠ¡1.4: å®ç°æ‰¹å¤„ç†å™¨
åˆ›å»º `src/core/processor.py`:

```python
from pathlib import Path
from typing import List, Dict, Optional
from concurrent.futures import ThreadPoolExecutor, as_completed
from tqdm import tqdm
import hashlib
from PIL import Image
import logging

from .detector import ImageDetector
from .database import DatabaseManager

logger = logging.getLogger(__name__)

class BatchProcessor:
    """æ‰¹é‡å›¾åƒå¤„ç†å™¨"""
    
    def __init__(
        self, 
        detector: Optional[ImageDetector] = None,
        db_manager: Optional[DatabaseManager] = None,
        cache_dir: Path = Path("cache")
    ):
        self.detector = detector or ImageDetector()
        self.db = db_manager or DatabaseManager()
        self.cache_dir = cache_dir
        self.cache_dir.mkdir(parents=True, exist_ok=True)
    
    def compute_hash(self, image_path: Path) -> str:
        """è®¡ç®—å›¾åƒå“ˆå¸Œå€¼ç”¨äºå»é‡"""
        with open(image_path, 'rb') as f:
            return hashlib.md5(f.read()).hexdigest()
    
    def extract_metadata(self, image_path: Path) -> Dict:
        """æå–å›¾åƒå…ƒæ•°æ®"""
        try:
            img = Image.open(image_path)
            return {
                "width": img.width,
                "height": img.height,
                "size": image_path.stat().st_size,
            }
        except Exception as e:
            logger.error(f"Failed to extract metadata from {image_path}: {e}")
            return {}
    
    def process_single_image(self, image_path: Path) -> Dict:
        """å¤„ç†å•å¼ å›¾åƒ"""
        # æ£€æŸ¥æ˜¯å¦å·²å¤„ç†
        existing = self.db.get_photo_by_path(str(image_path))
        if existing:
            logger.info(f"Skipping already processed: {image_path}")
            return {"status": "skipped", "path": str(image_path)}
        
        try:
            # è®¡ç®—å“ˆå¸Œ
            image_hash = self.compute_hash(image_path)
            
            # æå–å…ƒæ•°æ®
            metadata = self.extract_metadata(image_path)
            
            # AIæ£€æµ‹
            detection_result = self.detector.detect(image_path)
            
            # å‡†å¤‡æ•°æ®åº“è®°å½•
            photo_data = {
                "path": str(image_path),
                "hash": image_hash,
                **metadata,
                "category": detection_result.get("top_category"),
                "confidence": detection_result.get("confidence"),
                "classifications": detection_result.get("classifications"),
                "caption": detection_result.get("caption"),
            }
            
            # ä¿å­˜åˆ°æ•°æ®åº“
            photo_id = self.db.add_photo(photo_data)
            
            return {
                "status": "success",
                "path": str(image_path),
                "photo_id": photo_id,
                "category": photo_data["category"],
                "confidence": photo_data["confidence"]
            }
            
        except Exception as e:
            logger.error(f"Failed to process {image_path}: {e}")
            return {
                "status": "error",
                "path": str(image_path),
                "error": str(e)
            }
    
    def process_batch(
        self, 
        directory: Path,
        extensions: List[str] = ['.jpg', '.jpeg', '.png', '.webp'],
        max_workers: int = 4
    ) -> Dict:
        """æ‰¹é‡å¤„ç†ç›®å½•ä¸­çš„å›¾åƒ"""
        # æ”¶é›†å›¾åƒæ–‡ä»¶
        image_files = []
        for ext in extensions:
            image_files.extend(directory.glob(f"**/*{ext}"))
            image_files.extend(directory.glob(f"**/*{ext.upper()}"))
        
        if not image_files:
            return {
                "status": "no_images",
                "message": f"No images found in {directory}"
            }
        
        results = {
            "total": len(image_files),
            "processed": 0,
            "skipped": 0,
            "errors": 0,
            "details": []
        }
        
        # å¹¶è¡Œå¤„ç†
        with ThreadPoolExecutor(max_workers=max_workers) as executor:
            futures = {
                executor.submit(self.process_single_image, img): img 
                for img in image_files
            }
            
            # æ˜¾ç¤ºè¿›åº¦æ¡
            for future in tqdm(as_completed(futures), total=len(futures), desc="Processing"):
                result = future.result()
                results["details"].append(result)
                
                if result["status"] == "success":
                    results["processed"] += 1
                elif result["status"] == "skipped":
                    results["skipped"] += 1
                else:
                    results["errors"] += 1
        
        return results
```

### ä»»åŠ¡1.5: å®ç°OCRåŠŸèƒ½
åˆ›å»º `src/models/ocr_model.py`:

```python
from paddleocr import PaddleOCR
from pathlib import Path
from typing import List, Dict, Optional
import logging

logger = logging.getLogger(__name__)

class OCRExtractor:
    """OCRæ–‡å­—æå–å™¨"""
    
    def __init__(self, lang: str = "ch"):
        """
        åˆå§‹åŒ–OCRæ¨¡å‹
        
        Args:
            lang: è¯­è¨€è®¾ç½®ï¼Œ'ch'è¡¨ç¤ºä¸­è‹±æ–‡æ··åˆï¼Œ'en'è¡¨ç¤ºçº¯è‹±æ–‡
        """
        self.ocr = PaddleOCR(
            use_angle_cls=True,
            lang=lang,
            use_gpu=False,  # CPUæ¨¡å¼
            show_log=False
        )
    
    def extract_text(self, image_path: Path) -> Dict:
        """
        ä»å›¾åƒä¸­æå–æ–‡å­—
        
        Args:
            image_path: å›¾åƒæ–‡ä»¶è·¯å¾„
            
        Returns:
            åŒ…å«æå–æ–‡å­—å’Œç½®ä¿¡åº¦çš„å­—å…¸
        """
        if not image_path.exists():
            return {"error": "Image file not found", "text": ""}
        
        try:
            # OCRè¯†åˆ«
            result = self.ocr.ocr(str(image_path), cls=True)
            
            if not result or not result[0]:
                return {"text": "", "confidence": 0.0, "lines": []}
            
            # æå–æ–‡å­—è¡Œ
            lines = []
            all_text = []
            total_confidence = 0.0
            
            for line in result[0]:
                text = line[1][0]
                confidence = line[1][1]
                
                lines.append({
                    "text": text,
                    "confidence": confidence,
                    "bbox": line[0]
                })
                
                all_text.append(text)
                total_confidence += confidence
            
            # è®¡ç®—å¹³å‡ç½®ä¿¡åº¦
            avg_confidence = total_confidence / len(lines) if lines else 0.0
            
            return {
                "text": " ".join(all_text),
                "confidence": avg_confidence,
                "lines": lines,
                "line_count": len(lines)
            }
            
        except Exception as e:
            logger.error(f"OCR extraction failed for {image_path}: {e}")
            return {
                "error": str(e),
                "text": "",
                "confidence": 0.0,
                "lines": []
            }
    
    def is_document(self, ocr_result: Dict, min_lines: int = 5) -> bool:
        """
        åˆ¤æ–­å›¾åƒæ˜¯å¦ä¸ºæ–‡æ¡£ç±»å‹
        
        Args:
            ocr_result: OCRæå–ç»“æœ
            min_lines: æœ€å°‘æ–‡å­—è¡Œæ•°é˜ˆå€¼
            
        Returns:
            æ˜¯å¦ä¸ºæ–‡æ¡£
        """
        return ocr_result.get("line_count", 0) >= min_lines
```

### ä»»åŠ¡1.6: å®ç°FastAPIæ¥å£
åˆ›å»º `src/api/main.py`:

```python
from fastapi import FastAPI, HTTPException, UploadFile, File, Query
from fastapi.responses import JSONResponse
from pydantic import BaseModel
from typing import List, Optional, Dict
from pathlib import Path
import asyncio

from ..core.detector import ImageDetector
from ..core.database import DatabaseManager
from ..core.processor import BatchProcessor
from ..models.ocr_model import OCRExtractor

app = FastAPI(title="Vibe Photos API", version="1.0.0")

# åˆå§‹åŒ–ç»„ä»¶
detector = ImageDetector()
db_manager = DatabaseManager()
processor = BatchProcessor(detector, db_manager)
ocr = OCRExtractor()

class ImportRequest(BaseModel):
    directory: str
    extensions: List[str] = ['.jpg', '.jpeg', '.png']
    max_workers: int = 4

class SearchRequest(BaseModel):
    query: str
    category: Optional[str] = None
    min_confidence: float = 0.5
    limit: int = 50

class AnnotationRequest(BaseModel):
    photo_id: int
    user_label: str
    user_tags: Optional[List[str]] = []

@app.get("/")
async def root():
    """APIæ ¹è·¯å¾„"""
    return {
        "name": "Vibe Photos API",
        "version": "1.0.0",
        "status": "running"
    }

@app.post("/import/batch")
async def import_batch(request: ImportRequest):
    """æ‰¹é‡å¯¼å…¥ç…§ç‰‡"""
    directory = Path(request.directory)
    
    if not directory.exists():
        raise HTTPException(status_code=400, detail="Directory not found")
    
    # å¼‚æ­¥æ‰§è¡Œæ‰¹å¤„ç†
    loop = asyncio.get_event_loop()
    result = await loop.run_in_executor(
        None,
        processor.process_batch,
        directory,
        request.extensions,
        request.max_workers
    )
    
    return JSONResponse(content=result)

@app.post("/import/single")
async def import_single(file: UploadFile = File(...)):
    """å¯¼å…¥å•å¼ ç…§ç‰‡"""
    # ä¿å­˜ä¸Šä¼ æ–‡ä»¶
    temp_path = Path(f"temp/{file.filename}")
    temp_path.parent.mkdir(exist_ok=True)
    
    with open(temp_path, "wb") as f:
        content = await file.read()
        f.write(content)
    
    # å¤„ç†å›¾åƒ
    result = processor.process_single_image(temp_path)
    
    # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
    temp_path.unlink()
    
    return result

@app.post("/search")
async def search_photos(request: SearchRequest):
    """æœç´¢ç…§ç‰‡"""
    photos = db_manager.search_photos(
        query=request.query,
        category=request.category,
        min_confidence=request.min_confidence,
        limit=request.limit
    )
    
    results = []
    for photo in photos:
        results.append({
            "id": photo.id,
            "path": photo.path,
            "category": photo.category,
            "confidence": photo.confidence,
            "caption": photo.caption,
            "user_label": photo.user_label
        })
    
    return {
        "query": request.query,
        "count": len(results),
        "results": results
    }

@app.post("/annotate")
async def annotate_photo(request: AnnotationRequest):
    """æ ‡æ³¨ç…§ç‰‡"""
    updates = {
        "user_label": request.user_label,
        "user_tags": ",".join(request.user_tags) if request.user_tags else ""
    }
    
    success = db_manager.update_photo(request.photo_id, updates)
    
    if not success:
        raise HTTPException(status_code=404, detail="Photo not found")
    
    return {"status": "success", "photo_id": request.photo_id}

@app.post("/ocr/extract")
async def extract_text(photo_id: int):
    """æå–ç…§ç‰‡ä¸­çš„æ–‡å­—"""
    # è·å–ç…§ç‰‡ä¿¡æ¯
    photo = db_manager.Session().query(db_manager.Photo).filter_by(id=photo_id).first()
    
    if not photo:
        raise HTTPException(status_code=404, detail="Photo not found")
    
    # æ‰§è¡ŒOCR
    ocr_result = ocr.extract_text(Path(photo.path))
    
    # æ›´æ–°æ•°æ®åº“
    if ocr_result.get("text"):
        db_manager.update_photo(photo_id, {"ocr_text": ocr_result["text"]})
    
    return ocr_result

@app.get("/stats")
async def get_statistics():
    """è·å–ç³»ç»Ÿç»Ÿè®¡ä¿¡æ¯"""
    session = db_manager.Session()
    try:
        from sqlalchemy import func
        
        total_photos = session.query(func.count(db_manager.Photo.id)).scalar()
        
        category_stats = session.query(
            db_manager.Photo.category,
            func.count(db_manager.Photo.id).label("count"),
            func.avg(db_manager.Photo.confidence).label("avg_confidence")
        ).group_by(db_manager.Photo.category).all()
        
        return {
            "total_photos": total_photos,
            "categories": [
                {
                    "name": stat[0],
                    "count": stat[1],
                    "avg_confidence": round(stat[2], 2) if stat[2] else 0
                }
                for stat in category_stats
            ]
        }
    finally:
        session.close()
```

### ä»»åŠ¡1.7: å®ç°å‘½ä»¤è¡Œæ¥å£
åˆ›å»º `src/cli.py`:

```python
import typer
from pathlib import Path
from rich.console import Console
from rich.table import Table
from rich.progress import track
import json

from .core.detector import ImageDetector
from .core.database import DatabaseManager
from .core.processor import BatchProcessor
from .models.ocr_model import OCRExtractor

app = typer.Typer(help="Vibe Photos CLI - AIç…§ç‰‡ç®¡ç†å·¥å…·")
console = Console()

@app.command()
def import_photos(
    directory: Path = typer.Argument(..., help="ç…§ç‰‡ç›®å½•è·¯å¾„"),
    workers: int = typer.Option(4, help="å¹¶è¡Œå¤„ç†çº¿ç¨‹æ•°"),
    ocr: bool = typer.Option(False, help="æ˜¯å¦æå–æ–‡å­—")
):
    """æ‰¹é‡å¯¼å…¥ç…§ç‰‡"""
    console.print(f"[bold blue]æ­£åœ¨å¯¼å…¥ç…§ç‰‡ç›®å½•: {directory}[/bold blue]")
    
    processor = BatchProcessor()
    result = processor.process_batch(directory, max_workers=workers)
    
    # æ˜¾ç¤ºç»“æœ
    console.print(f"\n[green]å¯¼å…¥å®Œæˆ![/green]")
    console.print(f"æ€»è®¡: {result['total']} å¼ ")
    console.print(f"æˆåŠŸ: {result['processed']} å¼ ")
    console.print(f"è·³è¿‡: {result['skipped']} å¼ ")
    console.print(f"é”™è¯¯: {result['errors']} å¼ ")
    
    # å¦‚æœå¯ç”¨OCR
    if ocr and result['processed'] > 0:
        console.print("\n[yellow]æ­£åœ¨æå–æ–‡å­—...[/yellow]")
        ocr_extractor = OCRExtractor()
        # OCRå¤„ç†é€»è¾‘...

@app.command()
def search(
    query: str = typer.Argument(..., help="æœç´¢å…³é”®è¯"),
    category: str = typer.Option(None, help="æŒ‡å®šç±»åˆ«"),
    limit: int = typer.Option(20, help="ç»“æœæ•°é‡é™åˆ¶")
):
    """æœç´¢ç…§ç‰‡"""
    db = DatabaseManager()
    results = db.search_photos(query, category=category, limit=limit)
    
    if not results:
        console.print(f"[yellow]æœªæ‰¾åˆ°åŒ¹é…çš„ç…§ç‰‡[/yellow]")
        return
    
    # åˆ›å»ºè¡¨æ ¼
    table = Table(title=f"æœç´¢ç»“æœ: {query}")
    table.add_column("ID", style="cyan")
    table.add_column("è·¯å¾„", style="green")
    table.add_column("ç±»åˆ«", style="yellow")
    table.add_column("ç½®ä¿¡åº¦", style="magenta")
    table.add_column("æè¿°", style="white")
    
    for photo in results:
        table.add_row(
            str(photo.id),
            Path(photo.path).name,
            photo.category or "æœªçŸ¥",
            f"{photo.confidence:.1%}" if photo.confidence else "N/A",
            (photo.caption or "")[:50] + "..." if photo.caption and len(photo.caption) > 50 else photo.caption or ""
        )
    
    console.print(table)

@app.command()
def detect(
    image_path: Path = typer.Argument(..., help="å›¾åƒæ–‡ä»¶è·¯å¾„"),
    show_all: bool = typer.Option(False, help="æ˜¾ç¤ºæ‰€æœ‰åˆ†ç±»ç»“æœ")
):
    """æ£€æµ‹å•å¼ ç…§ç‰‡"""
    if not image_path.exists():
        console.print(f"[red]æ–‡ä»¶ä¸å­˜åœ¨: {image_path}[/red]")
        return
    
    detector = ImageDetector()
    result = detector.detect(image_path)
    
    # æ˜¾ç¤ºç»“æœ
    console.print(f"\n[bold]æ£€æµ‹ç»“æœ:[/bold]")
    console.print(f"æ–‡ä»¶: {image_path}")
    console.print(f"ä¸»è¦ç±»åˆ«: [yellow]{result['top_category']}[/yellow]")
    console.print(f"ç½®ä¿¡åº¦: [green]{result['confidence']:.1%}[/green]")
    console.print(f"æè¿°: {result['caption']}")
    
    if show_all:
        console.print("\n[bold]æ‰€æœ‰åˆ†ç±»:[/bold]")
        for label, score in result['classifications'].items():
            console.print(f"  {label}: {score:.1%}")

@app.command()
def stats():
    """æ˜¾ç¤ºç»Ÿè®¡ä¿¡æ¯"""
    db = DatabaseManager()
    session = db.Session()
    
    try:
        from sqlalchemy import func
        
        total = session.query(func.count(db.Photo.id)).scalar()
        
        if total == 0:
            console.print("[yellow]æ•°æ®åº“ä¸­æ²¡æœ‰ç…§ç‰‡[/yellow]")
            return
        
        # ç±»åˆ«ç»Ÿè®¡
        category_stats = session.query(
            db.Photo.category,
            func.count(db.Photo.id).label("count")
        ).group_by(db.Photo.category).order_by(func.count(db.Photo.id).desc()).all()
        
        console.print(f"\n[bold]ç…§ç‰‡ç»Ÿè®¡ä¿¡æ¯[/bold]")
        console.print(f"æ€»è®¡: {total} å¼ ç…§ç‰‡\n")
        
        table = Table(title="ç±»åˆ«åˆ†å¸ƒ")
        table.add_column("ç±»åˆ«", style="cyan")
        table.add_column("æ•°é‡", style="green")
        table.add_column("å æ¯”", style="yellow")
        
        for cat, count in category_stats:
            table.add_row(
                cat or "æœªåˆ†ç±»",
                str(count),
                f"{count/total:.1%}"
            )
        
        console.print(table)
        
    finally:
        session.close()

@app.command()
def export(
    query: str = typer.Argument(..., help="å¯¼å‡ºæ¡ä»¶ï¼ˆæœç´¢è¯æˆ–ç±»åˆ«ï¼‰"),
    output_dir: Path = typer.Argument(..., help="è¾“å‡ºç›®å½•"),
    format: str = typer.Option("json", help="å¯¼å‡ºæ ¼å¼: json/csv")
):
    """å¯¼å‡ºç…§ç‰‡æ•°æ®"""
    db = DatabaseManager()
    photos = db.search_photos(query, limit=10000)
    
    if not photos:
        console.print(f"[yellow]æ²¡æœ‰æ‰¾åˆ°åŒ¹é…çš„ç…§ç‰‡[/yellow]")
        return
    
    output_dir.mkdir(parents=True, exist_ok=True)
    
    if format == "json":
        output_file = output_dir / f"export_{query}.json"
        data = []
        for photo in photos:
            data.append({
                "id": photo.id,
                "path": photo.path,
                "category": photo.category,
                "confidence": photo.confidence,
                "caption": photo.caption,
                "ocr_text": photo.ocr_text,
                "user_label": photo.user_label
            })
        
        with open(output_file, "w", encoding="utf-8") as f:
            json.dump(data, f, ensure_ascii=False, indent=2)
    
    console.print(f"[green]æˆåŠŸå¯¼å‡º {len(photos)} å¼ ç…§ç‰‡åˆ° {output_file}[/green]")

if __name__ == "__main__":
    app()
```

### ä»»åŠ¡1.8: åˆ›å»ºæµ‹è¯•æ–‡ä»¶
åˆ›å»º `tests/test_detector.py`:

```python
import pytest
from pathlib import Path
from src.core.detector import ImageDetector
from src.core.database import DatabaseManager
from src.core.processor import BatchProcessor

@pytest.fixture
def detector():
    """åˆ›å»ºæ£€æµ‹å™¨å®ä¾‹"""
    return ImageDetector()

@pytest.fixture
def db_manager():
    """åˆ›å»ºæµ‹è¯•æ•°æ®åº“"""
    return DatabaseManager("data/test.db")

def test_detector_initialization(detector):
    """æµ‹è¯•æ£€æµ‹å™¨åˆå§‹åŒ–"""
    assert detector.siglip_model is not None
    assert detector.blip_model is not None

def test_image_detection(detector):
    """æµ‹è¯•å›¾åƒæ£€æµ‹"""
    # å‡è®¾æœ‰æµ‹è¯•å›¾åƒ
    test_image = Path("tests/fixtures/test_iphone.jpg")
    if test_image.exists():
        result = detector.detect(test_image)
        
        assert result["status"] == "success"
        assert "classifications" in result
        assert "caption" in result
        assert result["confidence"] > 0

def test_database_operations(db_manager):
    """æµ‹è¯•æ•°æ®åº“æ“ä½œ"""
    # æ·»åŠ ç…§ç‰‡
    photo_data = {
        "path": "/test/photo.jpg",
        "category": "ç”µå­äº§å“",
        "confidence": 0.95,
        "caption": "A smartphone on a desk"
    }
    
    photo_id = db_manager.add_photo(photo_data)
    assert photo_id > 0
    
    # æœç´¢ç…§ç‰‡
    results = db_manager.search_photos("ç”µå­äº§å“")
    assert len(results) > 0
    
    # æ›´æ–°ç…§ç‰‡
    success = db_manager.update_photo(photo_id, {"user_label": "iPhone 15"})
    assert success

def test_batch_processing(detector, db_manager):
    """æµ‹è¯•æ‰¹å¤„ç†"""
    processor = BatchProcessor(detector, db_manager)
    test_dir = Path("tests/fixtures")
    
    if test_dir.exists():
        result = processor.process_batch(test_dir, max_workers=2)
        
        assert result["total"] >= 0
        assert "processed" in result
        assert "errors" in result

# æ€§èƒ½æµ‹è¯•
def test_detection_performance(detector):
    """æµ‹è¯•æ£€æµ‹æ€§èƒ½"""
    import time
    
    test_image = Path("tests/fixtures/test_iphone.jpg")
    if test_image.exists():
        start = time.time()
        result = detector.detect(test_image)
        elapsed = time.time() - start
        
        # åº”è¯¥åœ¨2ç§’å†…å®Œæˆ
        assert elapsed < 2.0
        assert result["status"] == "success"
```

## ğŸ“‹ Phase 2: è¯­ä¹‰æœç´¢å¢å¼ºï¼ˆ1ä¸ªæœˆï¼‰

### ä»»åŠ¡2.1: å®ç°å‘é‡åµŒå…¥
åˆ›å»º `src/models/embedder.py`:

```python
from transformers import AutoModel, AutoProcessor
import torch
from PIL import Image
from pathlib import Path
from typing import List, Union
import numpy as np

class ImageEmbedder:
    """å›¾åƒå‘é‡åµŒå…¥å™¨"""
    
    def __init__(self, model_name: str = "google/siglip-base-patch16-224"):
        self.processor = AutoProcessor.from_pretrained(model_name)
        self.model = AutoModel.from_pretrained(model_name)
        self.model.eval()
    
    def encode_image(self, image_path: Path) -> np.ndarray:
        """ç¼–ç å•å¼ å›¾åƒä¸ºå‘é‡"""
        image = Image.open(image_path).convert("RGB")
        
        inputs = self.processor(images=image, return_tensors="pt")
        with torch.no_grad():
            outputs = self.model.get_image_features(**inputs)
            # å½’ä¸€åŒ–
            embeddings = outputs / outputs.norm(dim=-1, keepdim=True)
        
        return embeddings.numpy().squeeze()
    
    def encode_text(self, text: str) -> np.ndarray:
        """ç¼–ç æ–‡æœ¬æŸ¥è¯¢ä¸ºå‘é‡"""
        inputs = self.processor(text=text, return_tensors="pt", padding=True)
        with torch.no_grad():
            outputs = self.model.get_text_features(**inputs)
            embeddings = outputs / outputs.norm(dim=-1, keepdim=True)
        
        return embeddings.numpy().squeeze()
    
    def compute_similarity(self, vec1: np.ndarray, vec2: np.ndarray) -> float:
        """è®¡ç®—ä¸¤ä¸ªå‘é‡çš„ä½™å¼¦ç›¸ä¼¼åº¦"""
        return float(np.dot(vec1, vec2))
```

### ä»»åŠ¡2.2: å®ç°æ··åˆæœç´¢
åˆ›å»º `src/core/hybrid_searcher.py`:

```python
import numpy as np
from typing import List, Dict, Optional
import json
from pathlib import Path

from .database import DatabaseManager, Photo
from ..models.embedder import ImageEmbedder

class HybridSearcher:
    """æ··åˆæœç´¢å¼•æ“ - ç»“åˆæ–‡æœ¬å’Œè¯­ä¹‰æœç´¢"""
    
    def __init__(self, db_manager: DatabaseManager, embedder: Optional[ImageEmbedder] = None):
        self.db = db_manager
        self.embedder = embedder or ImageEmbedder()
        
    def search(
        self,
        query: str,
        mode: str = "hybrid",  # text, vector, hybrid
        limit: int = 50,
        alpha: float = 0.5  # æ–‡æœ¬æƒé‡ vs å‘é‡æƒé‡
    ) -> List[Dict]:
        """
        æ‰§è¡Œæœç´¢
        
        Args:
            query: æœç´¢æŸ¥è¯¢
            mode: æœç´¢æ¨¡å¼
            limit: ç»“æœé™åˆ¶
            alpha: æ··åˆæœç´¢ä¸­æ–‡æœ¬æœç´¢çš„æƒé‡ï¼ˆ0-1ï¼‰
        """
        
        if mode == "text":
            return self._text_search(query, limit)
        elif mode == "vector":
            return self._vector_search(query, limit)
        else:  # hybrid
            text_results = self._text_search(query, limit * 2)
            vector_results = self._vector_search(query, limit * 2)
            return self._merge_results(text_results, vector_results, alpha, limit)
    
    def _text_search(self, query: str, limit: int) -> List[Dict]:
        """çº¯æ–‡æœ¬æœç´¢"""
        photos = self.db.search_photos(query, limit=limit)
        
        results = []
        for i, photo in enumerate(photos):
            results.append({
                "id": photo.id,
                "path": photo.path,
                "score": 1.0 - (i / len(photos)),  # ç®€å•æ’ååˆ†æ•°
                "category": photo.category,
                "caption": photo.caption,
                "source": "text"
            })
        
        return results
    
    def _vector_search(self, query: str, limit: int) -> List[Dict]:
        """å‘é‡è¯­ä¹‰æœç´¢"""
        # ç¼–ç æŸ¥è¯¢
        query_embedding = self.embedder.encode_text(query)
        
        # è·å–æ‰€æœ‰å¸¦å‘é‡çš„ç…§ç‰‡
        session = self.db.Session()
        try:
            photos = session.query(Photo).filter(
                Photo.embedding_json.isnot(None)
            ).all()
            
            if not photos:
                return []
            
            # è®¡ç®—ç›¸ä¼¼åº¦
            similarities = []
            for photo in photos:
                try:
                    # è§£æå­˜å‚¨çš„å‘é‡
                    embedding = np.array(json.loads(photo.embedding_json))
                    similarity = self.embedder.compute_similarity(query_embedding, embedding)
                    similarities.append((photo, similarity))
                except:
                    continue
            
            # æ’åº
            similarities.sort(key=lambda x: x[1], reverse=True)
            
            # æ„å»ºç»“æœ
            results = []
            for photo, score in similarities[:limit]:
                results.append({
                    "id": photo.id,
                    "path": photo.path,
                    "score": float(score),
                    "category": photo.category,
                    "caption": photo.caption,
                    "source": "vector"
                })
            
            return results
            
        finally:
            session.close()
    
    def _merge_results(
        self,
        text_results: List[Dict],
        vector_results: List[Dict],
        alpha: float,
        limit: int
    ) -> List[Dict]:
        """åˆå¹¶æ–‡æœ¬å’Œå‘é‡æœç´¢ç»“æœ"""
        # åˆ›å»ºIDåˆ°ç»“æœçš„æ˜ å°„
        merged = {}
        
        # å¤„ç†æ–‡æœ¬ç»“æœ
        for result in text_results:
            photo_id = result["id"]
            if photo_id not in merged:
                merged[photo_id] = result.copy()
                merged[photo_id]["final_score"] = result["score"] * alpha
            else:
                merged[photo_id]["final_score"] += result["score"] * alpha
        
        # å¤„ç†å‘é‡ç»“æœ
        for result in vector_results:
            photo_id = result["id"]
            if photo_id not in merged:
                merged[photo_id] = result.copy()
                merged[photo_id]["final_score"] = result["score"] * (1 - alpha)
            else:
                merged[photo_id]["final_score"] += result["score"] * (1 - alpha)
                merged[photo_id]["source"] = "hybrid"
        
        # æ’åºå¹¶è¿”å›
        final_results = list(merged.values())
        final_results.sort(key=lambda x: x["final_score"], reverse=True)
        
        return final_results[:limit]
```

## ğŸ“‹ Phase 3: ç”Ÿäº§çº§ç³»ç»Ÿï¼ˆ3ä¸ªæœˆï¼‰

### ä»»åŠ¡3.1: PostgreSQL + pgvectoré…ç½®
åˆ›å»º `scripts/setup_postgres.sql`:

```sql
-- åˆ›å»ºæ•°æ®åº“
CREATE DATABASE vibe_photos;

-- è¿æ¥åˆ°æ•°æ®åº“
\c vibe_photos;

-- å®‰è£…pgvectoræ‰©å±•
CREATE EXTENSION IF NOT EXISTS vector;

-- åˆ›å»ºä¸»è¡¨
CREATE TABLE photos (
    id SERIAL PRIMARY KEY,
    path TEXT UNIQUE NOT NULL,
    hash VARCHAR(64),
    
    -- å…ƒæ•°æ®
    width INTEGER,
    height INTEGER,
    size BIGINT,
    taken_at TIMESTAMP,
    imported_at TIMESTAMP DEFAULT NOW(),
    
    -- AIç»“æœ
    category VARCHAR(100),
    confidence REAL,
    classifications JSONB,
    caption TEXT,
    ocr_text TEXT,
    
    -- å‘é‡åµŒå…¥ (768ç»´ for SigLIP-base)
    embedding vector(768),
    
    -- ç”¨æˆ·æ•°æ®
    user_label VARCHAR(200),
    user_tags TEXT[],
    is_favorite BOOLEAN DEFAULT FALSE,
    
    -- ç´¢å¼•æ ‡è®°
    indexed_at TIMESTAMP,
    updated_at TIMESTAMP DEFAULT NOW()
);

-- åˆ›å»ºç´¢å¼•
CREATE INDEX idx_photos_category ON photos(category);
CREATE INDEX idx_photos_confidence ON photos(confidence);
CREATE INDEX idx_photos_user_label ON photos(user_label);
CREATE INDEX idx_photos_taken_at ON photos(taken_at);
CREATE INDEX idx_photos_hash ON photos(hash);

-- åˆ›å»ºå‘é‡ç´¢å¼•ï¼ˆä½¿ç”¨HNSWç®—æ³•ï¼‰
CREATE INDEX idx_photos_embedding ON photos 
USING hnsw (embedding vector_cosine_ops)
WITH (m = 16, ef_construction = 64);

-- åˆ›å»ºå…¨æ–‡æœç´¢ç´¢å¼•
CREATE INDEX idx_photos_text_search ON photos 
USING gin(to_tsvector('simple', 
    COALESCE(caption, '') || ' ' || 
    COALESCE(ocr_text, '') || ' ' || 
    COALESCE(user_label, '')
));

-- åˆ›å»ºæ ‡æ³¨å†å²è¡¨
CREATE TABLE annotation_history (
    id SERIAL PRIMARY KEY,
    photo_id INTEGER REFERENCES photos(id) ON DELETE CASCADE,
    ai_prediction VARCHAR(100),
    user_correction VARCHAR(100),
    confidence REAL,
    created_at TIMESTAMP DEFAULT NOW()
);

-- åˆ›å»ºæ¨¡å‹ç‰ˆæœ¬è¡¨
CREATE TABLE model_versions (
    id SERIAL PRIMARY KEY,
    model_name VARCHAR(100) NOT NULL,
    version VARCHAR(50) NOT NULL,
    accuracy REAL,
    parameters JSONB,
    created_at TIMESTAMP DEFAULT NOW(),
    is_active BOOLEAN DEFAULT FALSE
);

-- åˆ›å»ºæœç´¢æ—¥å¿—è¡¨ï¼ˆç”¨äºåˆ†æå’Œä¼˜åŒ–ï¼‰
CREATE TABLE search_logs (
    id SERIAL PRIMARY KEY,
    query TEXT NOT NULL,
    mode VARCHAR(20),  -- text/vector/hybrid
    result_count INTEGER,
    response_time_ms INTEGER,
    user_feedback INTEGER,  -- 1-5è¯„åˆ†
    created_at TIMESTAMP DEFAULT NOW()
);
```

### ä»»åŠ¡3.2: é«˜çº§æœç´¢å®ç°
åˆ›å»º `src/core/advanced_searcher.py`:

```python
from typing import List, Dict, Optional
import asyncpg
import numpy as np
from datetime import datetime, timedelta

class AdvancedSearcher:
    """ç”Ÿäº§çº§é«˜çº§æœç´¢å¼•æ“"""
    
    def __init__(self, db_url: str):
        self.db_url = db_url
        
    async def search(
        self,
        query: str,
        filters: Optional[Dict] = None,
        limit: int = 50
    ) -> List[Dict]:
        """
        é«˜çº§æœç´¢with RRFï¼ˆReciprocal Rank Fusionï¼‰
        
        Args:
            query: æœç´¢æŸ¥è¯¢
            filters: è¿‡æ»¤æ¡ä»¶
            limit: ç»“æœé™åˆ¶
        """
        conn = await asyncpg.connect(self.db_url)
        
        try:
            # å‘é‡æœç´¢
            vector_results = await self._vector_search_pg(conn, query, filters, limit)
            
            # æ–‡æœ¬æœç´¢
            text_results = await self._text_search_pg(conn, query, filters, limit)
            
            # RRFèåˆ
            merged = self._rrf_merge(
                [vector_results, text_results],
                k=60  # RRFå¸¸æ•°
            )
            
            return merged[:limit]
            
        finally:
            await conn.close()
    
    async def _vector_search_pg(
        self,
        conn: asyncpg.Connection,
        query: str,
        filters: Optional[Dict],
        limit: int
    ) -> List[Dict]:
        """PostgreSQLå‘é‡æœç´¢"""
        # è¿™é‡Œéœ€è¦å…ˆå°†æŸ¥è¯¢ç¼–ç ä¸ºå‘é‡
        # query_embedding = self.embedder.encode_text(query)
        
        sql = """
            SELECT 
                id, path, category, caption,
                1 - (embedding <=> $1) as similarity
            FROM photos
            WHERE embedding IS NOT NULL
            ORDER BY embedding <=> $1
            LIMIT $2
        """
        
        # å®é™…å®ç°éœ€è¦ä¼ å…¥query_embedding
        rows = await conn.fetch(sql, query_embedding, limit)
        
        return [dict(row) for row in rows]
    
    async def _text_search_pg(
        self,
        conn: asyncpg.Connection,
        query: str,
        filters: Optional[Dict],
        limit: int
    ) -> List[Dict]:
        """PostgreSQLå…¨æ–‡æœç´¢"""
        sql = """
            SELECT 
                id, path, category, caption,
                ts_rank_cd(
                    to_tsvector('simple', 
                        COALESCE(caption, '') || ' ' || 
                        COALESCE(ocr_text, '')
                    ),
                    plainto_tsquery('simple', $1)
                ) as rank
            FROM photos
            WHERE 
                to_tsvector('simple', 
                    COALESCE(caption, '') || ' ' || 
                    COALESCE(ocr_text, '')
                ) @@ plainto_tsquery('simple', $1)
            ORDER BY rank DESC
            LIMIT $2
        """
        
        rows = await conn.fetch(sql, query, limit)
        return [dict(row) for row in rows]
    
    def _rrf_merge(self, result_lists: List[List[Dict]], k: int = 60) -> List[Dict]:
        """
        Reciprocal Rank Fusionç®—æ³•
        
        Args:
            result_lists: å¤šä¸ªæ’åºç»“æœåˆ—è¡¨
            k: RRFå¸¸æ•°ï¼ˆé€šå¸¸ä¸º60ï¼‰
        """
        scores = {}
        
        for results in result_lists:
            for rank, item in enumerate(results, 1):
                photo_id = item['id']
                if photo_id not in scores:
                    scores[photo_id] = {
                        'item': item,
                        'score': 0
                    }
                # RRFå…¬å¼: 1 / (k + rank)
                scores[photo_id]['score'] += 1.0 / (k + rank)
        
        # æ’åº
        sorted_items = sorted(
            scores.values(),
            key=lambda x: x['score'],
            reverse=True
        )
        
        return [item['item'] for item in sorted_items]
```

## ğŸ§ª æµ‹è¯•è§„èŒƒ

### å•å…ƒæµ‹è¯•è¦æ±‚
- æ¯ä¸ªæ ¸å¿ƒå‡½æ•°å¿…é¡»æœ‰å¯¹åº”çš„æµ‹è¯•
- æµ‹è¯•è¦†ç›–ç‡ç›®æ ‡: >80%
- ä½¿ç”¨pytestæ¡†æ¶
- Mockå¤–éƒ¨ä¾èµ–ï¼ˆæ¨¡å‹ã€æ•°æ®åº“ï¼‰

### é›†æˆæµ‹è¯•è¦æ±‚
- APIç«¯åˆ°ç«¯æµ‹è¯•
- æ•°æ®åº“äº‹åŠ¡æµ‹è¯•
- å¹¶å‘å¤„ç†æµ‹è¯•
- æ€§èƒ½åŸºå‡†æµ‹è¯•

### æµ‹è¯•æ•°æ®å‡†å¤‡
```python
# tests/conftest.py
import pytest
from pathlib import Path

@pytest.fixture
def test_images_dir():
    """æµ‹è¯•å›¾åƒç›®å½•"""
    return Path("tests/fixtures/images")

@pytest.fixture
def test_db():
    """æµ‹è¯•æ•°æ®åº“"""
    from src.core.database import DatabaseManager
    return DatabaseManager("data/test.db")

@pytest.fixture
def sample_image_data():
    """ç¤ºä¾‹å›¾åƒæ•°æ®"""
    return {
        "iphone": "tests/fixtures/iphone.jpg",
        "document": "tests/fixtures/document.png",
        "food": "tests/fixtures/pizza.jpg"
    }
```

## ğŸ“Š æ€§èƒ½è¦æ±‚

### Phase 1æ€§èƒ½æŒ‡æ ‡
- å›¾åƒå¤„ç†: <2ç§’/å¼ 
- æ‰¹å¤„ç†: >10å¼ /ç§’ï¼ˆå¹¶è¡Œï¼‰
- æœç´¢å“åº”: <1ç§’
- å†…å­˜ä½¿ç”¨: <2GB

### Phase 2æ€§èƒ½æŒ‡æ ‡
- å‘é‡ç¼–ç : <500ms/å¼ 
- æ··åˆæœç´¢: <500ms
- ç´¢å¼•æ›´æ–°: <100ms
- å†…å­˜ä½¿ç”¨: <4GB

### Phase 3æ€§èƒ½æŒ‡æ ‡
- å¹¶å‘ç”¨æˆ·: >100
- QPS: >1000
- P95å»¶è¿Ÿ: <500ms
- å¯ç”¨æ€§: >99.5%

## ğŸš€ éƒ¨ç½²æŒ‡å—

### å¼€å‘ç¯å¢ƒ
```bash
# 1. å…‹éš†ä»“åº“
git clone <repository>
cd vibe_photos_v3

# 2. å®‰è£…ä¾èµ–
uv venv
uv pip sync requirements.txt

# 3. è¿è¡Œå¼€å‘æœåŠ¡å™¨
uv run uvicorn src.api.main:app --reload --host 0.0.0.0 --port 8000

# 4. è¿è¡ŒCLI
uv run python -m src.cli --help
```

### ç”Ÿäº§ç¯å¢ƒ
```dockerfile
# Dockerfile
FROM python:3.12-slim

WORKDIR /app

# å®‰è£…ç³»ç»Ÿä¾èµ–
RUN apt-get update && apt-get install -y \
    libgomp1 \
    libglib2.0-0 \
    libsm6 \
    libxext6 \
    libxrender-dev \
    libgomp1 \
    wget \
    && rm -rf /var/lib/apt/lists/*

# å¤åˆ¶é¡¹ç›®æ–‡ä»¶
COPY . .

# å®‰è£…Pythonä¾èµ–
RUN pip install uv && \
    uv pip install -r requirements.txt

# æš´éœ²ç«¯å£
EXPOSE 8000

# å¯åŠ¨å‘½ä»¤
CMD ["uvicorn", "src.api.main:app", "--host", "0.0.0.0", "--port", "8000", "--workers", "4"]
```

## âœ… å®æ–½æ£€æŸ¥æ¸…å•

### Phase 1æ£€æŸ¥é¡¹ï¼ˆæ¯é¡¹å¿…é¡»å®Œæˆï¼‰
- [ ] ç¯å¢ƒé…ç½®å®Œæˆï¼ˆPython 3.12 + uvï¼‰
- [ ] SigLIP+BLIPæ¨¡å‹åŠ è½½æˆåŠŸ
- [ ] æ•°æ®åº“åˆ›å»ºå’Œè¿æ¥æ­£å¸¸
- [ ] æ‰¹é‡å¯¼å…¥åŠŸèƒ½å·¥ä½œ
- [ ] åŸºç¡€æœç´¢åŠŸèƒ½å®ç°
- [ ] CLIå·¥å…·å¯ç”¨
- [ ] APIæ¥å£å“åº”æ­£å¸¸
- [ ] å•å…ƒæµ‹è¯•é€šè¿‡ç‡>80%
- [ ] å¤„ç†1000å¼ å›¾ç‰‡æ— é”™è¯¯
- [ ] æ–‡æ¡£å®Œæ•´

### Phase 2æ£€æŸ¥é¡¹
- [ ] å‘é‡åµŒå…¥åŠŸèƒ½å®ç°
- [ ] æ··åˆæœç´¢å·¥ä½œæ­£å¸¸
- [ ] æœç´¢å‡†ç¡®ç‡æå‡>20%
- [ ] OCRåŠŸèƒ½é›†æˆå®Œæˆ
- [ ] Web UIå¯è®¿é—®
- [ ] æ€§èƒ½è¾¾åˆ°æŒ‡æ ‡

### Phase 3æ£€æŸ¥é¡¹
- [ ] PostgreSQL+pgvectoréƒ¨ç½²
- [ ] é«˜çº§æœç´¢ç®—æ³•å®ç°
- [ ] ç”Ÿäº§çº§ç›‘æ§é…ç½®
- [ ] è´Ÿè½½æµ‹è¯•é€šè¿‡
- [ ] æ–‡æ¡£å’ŒåŸ¹è®­å®Œæˆ

## ğŸ“š å‚è€ƒèµ„æº

### æ¨¡å‹æ–‡æ¡£
- [SigLIPæ¨¡å‹](https://huggingface.co/google/siglip-base-patch16-224-i18n)
- [BLIPæ¨¡å‹](https://huggingface.co/Salesforce/blip-image-captioning-base)
- [PaddleOCR](https://github.com/PaddlePaddle/PaddleOCR)

### æŠ€æœ¯æ–‡æ¡£
- [FastAPIæ–‡æ¡£](https://fastapi.tiangolo.com/)
- [pgvectoræ–‡æ¡£](https://github.com/pgvector/pgvector)
- [uvåŒ…ç®¡ç†å™¨](https://github.com/astral-sh/uv)

## ğŸ”§ æ•…éšœæ’æŸ¥

### å¸¸è§é—®é¢˜å’Œè§£å†³æ–¹æ¡ˆ

1. **æ¨¡å‹ä¸‹è½½å¤±è´¥**
   ```bash
   # æ‰‹åŠ¨ä¸‹è½½æ¨¡å‹
   python -c "from transformers import AutoModel; AutoModel.from_pretrained('google/siglip-base-patch16-224-i18n')"
   ```

2. **å†…å­˜ä¸è¶³**
   - å‡å°‘batch_size
   - ä½¿ç”¨æ¨¡å‹é‡åŒ–
   - å¯ç”¨æ¢¯åº¦æ£€æŸ¥ç‚¹

3. **OCRä¸­æ–‡è¯†åˆ«é—®é¢˜**
   - ç¡®ä¿PaddleOCRä½¿ç”¨'ch'æ¨¡å¼
   - æ£€æŸ¥å­—ä½“æ–‡ä»¶

4. **æ•°æ®åº“è¿æ¥é—®é¢˜**
   - æ£€æŸ¥PostgreSQLæœåŠ¡çŠ¶æ€
   - éªŒè¯è¿æ¥å­—ç¬¦ä¸²
   - ç¡®è®¤pgvectoræ‰©å±•å·²å®‰è£…

---

## ğŸ“Œ é‡è¦æé†’

### ç»™Coding AIçš„ç‰¹åˆ«è¯´æ˜

1. **ä¸¥æ ¼éµå¾ªPython 3.12å’Œuv**ï¼šä¸è¦ä½¿ç”¨pipæˆ–å…¶ä»–åŒ…ç®¡ç†å™¨
2. **å‡½æ•°å¼ç¼–ç¨‹ä¼˜å…ˆ**ï¼šé¿å…ä¸å¿…è¦çš„ç±»å’Œç»§æ‰¿
3. **æ—©æœŸè¿”å›æ¨¡å¼**ï¼šå¤„ç†é”™è¯¯å’Œè¾¹ç•Œæƒ…å†µè¦å°½æ—©è¿”å›
4. **å¼‚æ­¥ä¼˜å…ˆ**ï¼šä½¿ç”¨async/awaitå¤„ç†I/Oæ“ä½œ
5. **ç±»å‹æ³¨è§£å¿…é¡»**ï¼šæ‰€æœ‰å‡½æ•°ç­¾åå¿…é¡»æœ‰ç±»å‹æç¤º
6. **PydanticéªŒè¯**ï¼šä½¿ç”¨Pydanticæ¨¡å‹è¿›è¡Œè¾“å…¥éªŒè¯
7. **é”™è¯¯å¤„ç†å®Œæ•´**ï¼šæ¯ä¸ªå¯èƒ½å¤±è´¥çš„æ“ä½œéƒ½è¦æœ‰é”™è¯¯å¤„ç†
8. **æ—¥å¿—è®°å½•å……åˆ†**ï¼šå…³é”®æ“ä½œå¿…é¡»è®°å½•æ—¥å¿—
9. **æµ‹è¯•é©±åŠ¨å¼€å‘**ï¼šå…ˆå†™æµ‹è¯•ï¼Œå†å†™å®ç°
10. **æ–‡æ¡£å³ä»£ç **ï¼šä»£ç æ³¨é‡Šè¦æ¸…æ™°å®Œæ•´

### ä»£ç è´¨é‡è¦æ±‚

```python
# âœ… å¥½çš„ç¤ºä¾‹
async def process_image(
    image_path: Path,
    confidence_threshold: float = 0.5
) -> Dict[str, Any]:
    """å¤„ç†å•å¼ å›¾åƒå¹¶è¿”å›æ£€æµ‹ç»“æœ"""
    # æ—©æœŸéªŒè¯
    if not image_path.exists():
        logger.error(f"Image not found: {image_path}")
        return {"error": "Image not found", "path": str(image_path)}
    
    try:
        # å¤„ç†é€»è¾‘
        result = await detect_objects(image_path)
        
        # è¿‡æ»¤ä½ç½®ä¿¡åº¦ç»“æœ
        if result.confidence < confidence_threshold:
            return {"status": "low_confidence", "confidence": result.confidence}
        
        return {"status": "success", "data": result}
        
    except Exception as e:
        logger.exception(f"Processing failed for {image_path}")
        return {"error": str(e), "path": str(image_path)}

# âŒ é¿å…çš„ç¤ºä¾‹
def process_image(path):
    result = detect_objects(path)
    if result:
        return result
    else:
        return None
```

---

**æ–‡æ¡£ç‰ˆæœ¬**: 1.0.0
**æœ€åæ›´æ–°**: 2024-11-12
**ç›®æ ‡å—ä¼—**: Coding AI
**é¡¹ç›®çŠ¶æ€**: å¼€å‘ä¸­
