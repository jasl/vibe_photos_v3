# ğŸ”§ AIä»£ç è§„èŒƒ - Vibe Photosç¼–ç æ ‡å‡†

> æœ¬æ–‡æ¡£ä¸ºCoding AIæä¾›è¯¦ç»†çš„ä»£ç è§„èŒƒå’Œæœ€ä½³å®è·µï¼Œç¡®ä¿ä»£ç è´¨é‡å’Œä¸€è‡´æ€§

## ğŸŒ è¯­è¨€ä½¿ç”¨è§„èŒƒ

### æ ¸å¿ƒåŸåˆ™ï¼šä»£ç è‹±æ–‡ï¼Œæ–‡æ¡£ä¸­æ–‡

| æ–‡ä»¶ç±»å‹ | è¯­è¨€è¦æ±‚ | è¯´æ˜ | ç¤ºä¾‹ |
|---------|---------|------|------|
| **æºä»£ç æ–‡ä»¶** | çº¯è‹±æ–‡ | æ‰€æœ‰ä»£ç ã€æ³¨é‡Šã€æ–‡æ¡£å­—ç¬¦ä¸²å¿…é¡»ä½¿ç”¨è‹±æ–‡ | `.py`, `.js`, `.yaml` |
| **æ–‡æ¡£æ–‡ä»¶** | ä¸­æ–‡ | é¢å‘ç”¨æˆ·çš„æ–‡æ¡£ä½¿ç”¨ä¸­æ–‡ | `.md` æ–‡æ¡£ |
| **é…ç½®æ–‡ä»¶** | è‹±æ–‡ | é…ç½®é”®å€¼å¯¹ä½¿ç”¨è‹±æ–‡ | `config.yaml`, `settings.json` |
| **æµ‹è¯•æ–‡ä»¶** | è‹±æ–‡ | æµ‹è¯•ä»£ç å’Œæ³¨é‡Šä½¿ç”¨è‹±æ–‡ | `test_*.py` |
| **æäº¤ä¿¡æ¯** | ä¸­æ–‡/è‹±æ–‡ | å¯ä»¥ä½¿ç”¨ä¸­æ–‡è¯´æ˜ï¼Œä½†ç±»å‹æ ‡è¯†ç”¨è‹±æ–‡ | `feat:`, `fix:`, `docs:` |

### æºä»£ç è‹±æ–‡è§„èŒƒ

```python
# âœ… æ­£ç¡®ç¤ºä¾‹ - å…¨è‹±æ–‡
class ImageDetector:
    """
    Image detection module using SigLIP and BLIP models.
    
    This module provides functionality to detect and classify
    images using state-of-the-art AI models.
    """
    
    def detect_objects(self, image_path: Path) -> Dict:
        """
        Detect objects in the given image.
        
        Args:
            image_path: Path to the image file
            
        Returns:
            Dictionary containing detection results
        """
        # Check if file exists
        if not image_path.exists():
            logger.error(f"Image file not found: {image_path}")
            return {"error": "File not found"}
        
        # Process the image
        result = self._process_image(image_path)
        
        return result

# âŒ é”™è¯¯ç¤ºä¾‹ - æ··ç”¨ä¸­æ–‡
class ImageDetector:
    """
    å›¾åƒæ£€æµ‹æ¨¡å—  # é”™è¯¯ï¼šä½¿ç”¨äº†ä¸­æ–‡
    """
    
    def detect_objects(self, image_path: Path) -> Dict:
        # æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å­˜åœ¨  # é”™è¯¯ï¼šæ³¨é‡Šä½¿ç”¨äº†ä¸­æ–‡
        if not image_path.exists():
            logger.error(f"å›¾ç‰‡æœªæ‰¾åˆ°: {image_path}")  # é”™è¯¯ï¼šæ—¥å¿—ä¿¡æ¯ä½¿ç”¨äº†ä¸­æ–‡
            return {"error": "æ–‡ä»¶ä¸å­˜åœ¨"}  # é”™è¯¯ï¼šé”™è¯¯ä¿¡æ¯ä½¿ç”¨äº†ä¸­æ–‡
```

### æ–‡æ¡£æ–‡ä»¶ä¸­æ–‡è§„èŒƒ

```markdown
# âœ… æ­£ç¡®ç¤ºä¾‹ - æ–‡æ¡£ä½¿ç”¨ä¸­æ–‡

## å›¾åƒæ£€æµ‹æ¨¡å—ä½¿ç”¨è¯´æ˜

æœ¬æ¨¡å—æä¾›äº†å¼ºå¤§çš„å›¾åƒæ£€æµ‹åŠŸèƒ½ï¼Œæ”¯æŒä»¥ä¸‹ç‰¹æ€§ï¼š
- å¤šè¯­è¨€åˆ†ç±»ï¼ˆæ”¯æŒä¸­æ–‡æ ‡ç­¾ï¼‰
- æ‰¹é‡å¤„ç†
- è‡ªåŠ¨ç¼“å­˜

### ä½¿ç”¨ç¤ºä¾‹
\```python
# ä»£ç éƒ¨åˆ†ä»ç„¶ä¿æŒè‹±æ–‡
detector = ImageDetector()
result = detector.detect("image.jpg")
\```
```

### ç‰¹æ®Šæƒ…å†µå¤„ç†

1. **ç”¨æˆ·ç•Œé¢æ–‡æœ¬**ï¼šå­˜å‚¨åœ¨ç‹¬ç«‹çš„æœ¬åœ°åŒ–æ–‡ä»¶ä¸­
   ```python
   # messages_zh.py
   MESSAGES = {
       "welcome": "æ¬¢è¿ä½¿ç”¨Vibe Photos",
       "processing": "æ­£åœ¨å¤„ç†å›¾ç‰‡...",
       "complete": "å¤„ç†å®Œæˆ"
   }
   
   # main.py (è‹±æ–‡)
   from locales.messages_zh import MESSAGES
   print(MESSAGES["welcome"])  # Output Chinese text
   ```

2. **é…ç½®æ–‡ä»¶æ³¨é‡Š**ï¼šä½¿ç”¨è‹±æ–‡
   ```yaml
   # config.yaml
   # Database configuration
   database:
     host: localhost  # Database host address
     port: 5432      # PostgreSQL default port
   ```

3. **æ—¥å¿—è¾“å‡º**ï¼šå…³é”®ä¿¡æ¯ç”¨è‹±æ–‡ï¼Œç”¨æˆ·æç¤ºå¯æœ¬åœ°åŒ–
   ```python
   # System logs in English
   logger.info("Starting image processing")
   logger.error("Database connection failed")
   
   # User messages can be localized
   print(MESSAGES["processing"])  # æ˜¾ç¤ºä¸­æ–‡ç»™ç”¨æˆ·
   ```

### å‘½åè§„èŒƒå¯¹ç…§è¡¨

| æ¦‚å¿µ | è‹±æ–‡å‘½å | è¯´æ˜ |
|------|---------|------|
| æ£€æµ‹å™¨ | detector | ä¸ç”¨ jiance_qi |
| å¤„ç†å™¨ | processor | ä¸ç”¨ chuli_qi |
| æ•°æ®åº“ | database | ä¸ç”¨ shuju_ku |
| æœç´¢ | search | ä¸ç”¨ sousuo |
| å›¾åƒ | image | ä¸ç”¨ tupian |
| åˆ†ç±» | category/classify | ä¸ç”¨ fenlei |
| æ ‡ç­¾ | label/tag | ä¸ç”¨ biaoqian |
| ç”¨æˆ· | user | ä¸ç”¨ yonghu |

## ğŸ“ Pythonä»£ç è§„èŒƒ

### æ–‡ä»¶ç»„ç»‡ç»“æ„
```python
"""
æ¨¡å—æ–‡æ¡£å­—ç¬¦ä¸² - ç®€è¦è¯´æ˜æ¨¡å—åŠŸèƒ½
"""
# æ ‡å‡†åº“å¯¼å…¥
import os
import sys
from pathlib import Path
from typing import Dict, List, Optional, Union

# ç¬¬ä¸‰æ–¹åº“å¯¼å…¥
import torch
import numpy as np
from fastapi import FastAPI, HTTPException
from pydantic import BaseModel, Field

# æœ¬åœ°æ¨¡å—å¯¼å…¥
from .core import detector
from .utils import logger

# æ¨¡å—çº§å¸¸é‡ï¼ˆå…¨å¤§å†™ï¼‰
DEFAULT_BATCH_SIZE = 16
MAX_IMAGE_SIZE = (1920, 1080)

# æ¨¡å—çº§å˜é‡ï¼ˆå°å†™ï¼‰
_cache = {}
logger = logger.get_logger(__name__)

# ç±»å®šä¹‰
class ImageProcessor:
    """ç±»æ–‡æ¡£å­—ç¬¦ä¸²"""
    pass

# å‡½æ•°å®šä¹‰
def process_image(image_path: Path) -> Dict:
    """å‡½æ•°æ–‡æ¡£å­—ç¬¦ä¸²"""
    pass

# ä¸»ç¨‹åºå…¥å£
if __name__ == "__main__":
    main()
```

### å‘½åè§„èŒƒ
```python
# âœ… æ­£ç¡®çš„å‘½åç¤ºä¾‹

# å˜é‡åï¼šå°å†™ï¼Œä¸‹åˆ’çº¿åˆ†éš”ï¼Œæè¿°æ€§
user_input = "search query"
is_valid = True
has_permission = False
image_count = 42

# å‡½æ•°åï¼šå°å†™ï¼Œä¸‹åˆ’çº¿åˆ†éš”ï¼ŒåŠ¨è¯å¼€å¤´
def process_image(image_path: Path) -> Dict:
    pass

def validate_input(data: str) -> bool:
    pass

def get_user_settings(user_id: int) -> Dict:
    pass

# ç±»åï¼šå¤§é©¼å³°ï¼Œåè¯
class ImageDetector:
    pass

class DatabaseManager:
    pass

# å¸¸é‡ï¼šå…¨å¤§å†™ï¼Œä¸‹åˆ’çº¿åˆ†éš”
MAX_RETRY_COUNT = 3
DEFAULT_TIMEOUT = 30
API_VERSION = "1.0.0"

# ç§æœ‰æˆå‘˜ï¼šå•ä¸‹åˆ’çº¿å‰ç¼€
class MyClass:
    def __init__(self):
        self._internal_state = {}
    
    def _private_method(self):
        pass

# âŒ é¿å…çš„å‘½å
# å•å­—æ¯å˜é‡ï¼ˆé™¤äº†å¾ªç¯è®¡æ•°å™¨ï¼‰
x = process()  # é”™è¯¯
result = process()  # æ­£ç¡®

# ç¼©å†™ä¸æ¸…æ™°
def calc_img_sim():  # é”™è¯¯
def calculate_image_similarity():  # æ­£ç¡®

# åŒˆç‰™åˆ©å‘½åæ³•
strName = "john"  # é”™è¯¯
name = "john"  # æ­£ç¡®
```

### ç±»å‹æ³¨è§£è§„èŒƒ
```python
from typing import Dict, List, Optional, Union, Tuple, Any, Callable
from pathlib import Path
import numpy as np

# åŸºç¡€ç±»å‹æ³¨è§£
def process_text(text: str) -> str:
    return text.upper()

# å¯é€‰ç±»å‹
def search(
    query: str,
    limit: Optional[int] = None,
    category: Optional[str] = None
) -> List[Dict]:
    pass

# è”åˆç±»å‹
def load_image(source: Union[str, Path, bytes]) -> np.ndarray:
    pass

# å¤æ‚ç±»å‹
def batch_process(
    images: List[Path],
    processor: Callable[[Path], Dict],
    options: Dict[str, Any] = None
) -> List[Dict[str, Union[str, float]]]:
    pass

# è¿”å›å¤šä¸ªå€¼
def detect_objects(image: np.ndarray) -> Tuple[List[str], List[float]]:
    labels = ["cat", "dog"]
    scores = [0.9, 0.8]
    return labels, scores

# ä½¿ç”¨TypedDictå®šä¹‰å¤æ‚ç»“æ„
from typing import TypedDict

class DetectionResult(TypedDict):
    category: str
    confidence: float
    bbox: List[int]
    metadata: Optional[Dict]

def detect(image_path: Path) -> DetectionResult:
    return {
        "category": "electronic",
        "confidence": 0.95,
        "bbox": [10, 20, 100, 200],
        "metadata": None
    }
```

### å‡½æ•°è®¾è®¡åŸåˆ™
```python
# 1. å•ä¸€èŒè´£åŸåˆ™ - æ¯ä¸ªå‡½æ•°åªåšä¸€ä»¶äº‹
# âœ… å¥½çš„ç¤ºä¾‹
def load_image(path: Path) -> np.ndarray:
    """åŠ è½½å›¾åƒæ–‡ä»¶"""
    return cv2.imread(str(path))

def resize_image(image: np.ndarray, size: Tuple[int, int]) -> np.ndarray:
    """è°ƒæ•´å›¾åƒå¤§å°"""
    return cv2.resize(image, size)

# âŒ ä¸å¥½çš„ç¤ºä¾‹
def load_and_process_image(path: Path) -> np.ndarray:
    """åŠ è½½å¹¶å¤„ç†å›¾åƒï¼ˆåšäº†å¤ªå¤šäº‹ï¼‰"""
    image = cv2.imread(str(path))
    image = cv2.resize(image, (224, 224))
    image = normalize(image)
    return image

# 2. æ—©æœŸè¿”å›æ¨¡å¼ - å°½æ—©å¤„ç†é”™è¯¯æƒ…å†µ
def process_data(data: Optional[Dict]) -> Dict:
    # æ—©æœŸéªŒè¯
    if data is None:
        logger.warning("No data provided")
        return {}
    
    if not data.get("images"):
        logger.warning("No images in data")
        return {"error": "No images"}
    
    # ä¸»è¦é€»è¾‘ï¼ˆhappy pathï¼‰
    results = []
    for image in data["images"]:
        result = process_image(image)
        results.append(result)
    
    return {"results": results, "count": len(results)}

# 3. ä½¿ç”¨é»˜è®¤å‚æ•°è€ŒéNoneæ£€æŸ¥
# âœ… å¥½çš„ç¤ºä¾‹
def search(query: str, limit: int = 10, filters: Dict = None) -> List:
    filters = filters or {}
    # ç»§ç»­å¤„ç†
    
# âŒ ä¸å¥½çš„ç¤ºä¾‹
def search(query: str, limit: Optional[int], filters: Optional[Dict]) -> List:
    if limit is None:
        limit = 10
    if filters is None:
        filters = {}
    # ç»§ç»­å¤„ç†

# 4. å‚æ•°éªŒè¯å’Œé”™è¯¯å¤„ç†
def divide(a: float, b: float) -> float:
    """å®‰å…¨çš„é™¤æ³•æ“ä½œ"""
    if not isinstance(a, (int, float)) or not isinstance(b, (int, float)):
        raise TypeError("Arguments must be numbers")
    
    if b == 0:
        raise ValueError("Cannot divide by zero")
    
    return a / b

# 5. ä½¿ç”¨ä¸Šä¸‹æ–‡ç®¡ç†å™¨
from contextlib import contextmanager

@contextmanager
def temporary_directory():
    """åˆ›å»ºä¸´æ—¶ç›®å½•çš„ä¸Šä¸‹æ–‡ç®¡ç†å™¨"""
    import tempfile
    import shutil
    
    temp_dir = tempfile.mkdtemp()
    try:
        yield Path(temp_dir)
    finally:
        shutil.rmtree(temp_dir)

# ä½¿ç”¨
with temporary_directory() as temp_dir:
    # åœ¨ä¸´æ—¶ç›®å½•ä¸­æ“ä½œ
    process_files(temp_dir)
```

### å¼‚æ­¥ç¼–ç¨‹è§„èŒƒ
```python
import asyncio
from typing import List, Dict
import aiohttp
import aiofiles

# å¼‚æ­¥å‡½æ•°å®šä¹‰
async def fetch_data(url: str) -> Dict:
    """å¼‚æ­¥è·å–æ•°æ®"""
    async with aiohttp.ClientSession() as session:
        async with session.get(url) as response:
            return await response.json()

# å¼‚æ­¥æ–‡ä»¶æ“ä½œ
async def read_file_async(path: Path) -> str:
    """å¼‚æ­¥è¯»å–æ–‡ä»¶"""
    async with aiofiles.open(path, mode='r') as f:
        content = await f.read()
    return content

# å¹¶å‘æ‰§è¡Œå¤šä¸ªå¼‚æ­¥ä»»åŠ¡
async def process_batch_async(urls: List[str]) -> List[Dict]:
    """å¹¶å‘å¤„ç†å¤šä¸ªURL"""
    tasks = [fetch_data(url) for url in urls]
    results = await asyncio.gather(*tasks, return_exceptions=True)
    
    # è¿‡æ»¤æ‰å¼‚å¸¸
    valid_results = []
    for result in results:
        if not isinstance(result, Exception):
            valid_results.append(result)
        else:
            logger.error(f"Failed to fetch: {result}")
    
    return valid_results

# å¼‚æ­¥ç”Ÿæˆå™¨
async def read_large_file_chunks(path: Path, chunk_size: int = 1024):
    """å¼‚æ­¥è¯»å–å¤§æ–‡ä»¶çš„ç”Ÿæˆå™¨"""
    async with aiofiles.open(path, mode='rb') as f:
        while True:
            chunk = await f.read(chunk_size)
            if not chunk:
                break
            yield chunk

# å¼‚æ­¥ä¸Šä¸‹æ–‡ç®¡ç†å™¨
class AsyncDatabaseConnection:
    async def __aenter__(self):
        self.conn = await asyncpg.connect('postgresql://...')
        return self.conn
    
    async def __aexit__(self, exc_type, exc_val, exc_tb):
        await self.conn.close()

# ä½¿ç”¨å¼‚æ­¥ä¸Šä¸‹æ–‡ç®¡ç†å™¨
async with AsyncDatabaseConnection() as conn:
    result = await conn.fetch('SELECT * FROM photos')
```

### é”™è¯¯å¤„ç†è§„èŒƒ
```python
from typing import Optional, Union
import logging

logger = logging.getLogger(__name__)

# 1. ä½¿ç”¨è‡ªå®šä¹‰å¼‚å¸¸
class VibePhotosError(Exception):
    """åŸºç¡€å¼‚å¸¸ç±»"""
    pass

class ImageNotFoundError(VibePhotosError):
    """å›¾åƒæœªæ‰¾åˆ°å¼‚å¸¸"""
    pass

class ProcessingError(VibePhotosError):
    """å¤„ç†é”™è¯¯å¼‚å¸¸"""
    pass

# 2. æ˜ç¡®çš„é”™è¯¯å¤„ç†
def safe_process_image(image_path: Path) -> Optional[Dict]:
    """å®‰å…¨çš„å›¾åƒå¤„ç†ï¼ŒåŒ…å«å®Œæ•´é”™è¯¯å¤„ç†"""
    try:
        # æ£€æŸ¥æ–‡ä»¶å­˜åœ¨
        if not image_path.exists():
            raise ImageNotFoundError(f"Image not found: {image_path}")
        
        # æ£€æŸ¥æ–‡ä»¶å¤§å°
        file_size = image_path.stat().st_size
        if file_size > 100 * 1024 * 1024:  # 100MB
            raise ProcessingError("File too large")
        
        # å¤„ç†å›¾åƒ
        result = process_image(image_path)
        
        return result
        
    except ImageNotFoundError as e:
        logger.warning(f"Image not found: {e}")
        return None
        
    except ProcessingError as e:
        logger.error(f"Processing failed: {e}")
        return None
        
    except Exception as e:
        logger.exception(f"Unexpected error processing {image_path}")
        raise  # é‡æ–°æŠ›å‡ºæœªé¢„æœŸçš„å¼‚å¸¸

# 3. ä½¿ç”¨Resultç±»å‹æ¨¡å¼
from dataclasses import dataclass
from typing import Generic, TypeVar

T = TypeVar('T')

@dataclass
class Result(Generic[T]):
    """ç»“æœåŒ…è£…ç±»ï¼ŒåŒ…å«æˆåŠŸå€¼æˆ–é”™è¯¯"""
    value: Optional[T] = None
    error: Optional[str] = None
    
    @property
    def is_success(self) -> bool:
        return self.error is None
    
    @property
    def is_failure(self) -> bool:
        return self.error is not None
    
    @classmethod
    def success(cls, value: T) -> 'Result[T]':
        return cls(value=value)
    
    @classmethod
    def failure(cls, error: str) -> 'Result[T]':
        return cls(error=error)

def divide_safe(a: float, b: float) -> Result[float]:
    """å®‰å…¨é™¤æ³•ï¼Œè¿”å›Result"""
    if b == 0:
        return Result.failure("Division by zero")
    return Result.success(a / b)

# ä½¿ç”¨Result
result = divide_safe(10, 2)
if result.is_success:
    print(f"Result: {result.value}")
else:
    print(f"Error: {result.error}")

# 4. é‡è¯•æœºåˆ¶
from functools import wraps
import time

def retry(max_attempts: int = 3, delay: float = 1.0):
    """é‡è¯•è£…é¥°å™¨"""
    def decorator(func):
        @wraps(func)
        def wrapper(*args, **kwargs):
            for attempt in range(max_attempts):
                try:
                    return func(*args, **kwargs)
                except Exception as e:
                    if attempt == max_attempts - 1:
                        raise
                    logger.warning(f"Attempt {attempt + 1} failed: {e}")
                    time.sleep(delay * (2 ** attempt))  # æŒ‡æ•°é€€é¿
            return None
        return wrapper
    return decorator

@retry(max_attempts=3, delay=1.0)
def unreliable_operation():
    """å¯èƒ½å¤±è´¥çš„æ“ä½œ"""
    import random
    if random.random() < 0.7:
        raise ConnectionError("Network error")
    return "Success"
```

### æ—¥å¿—è§„èŒƒ
```python
import logging
from functools import wraps
import time

# é…ç½®æ—¥å¿—
def setup_logging(level: str = "INFO"):
    """é…ç½®æ—¥å¿—ç³»ç»Ÿ"""
    logging.basicConfig(
        level=level,
        format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
        handlers=[
            logging.FileHandler('app.log'),
            logging.StreamHandler()
        ]
    )

# è·å–logger
logger = logging.getLogger(__name__)

# æ—¥å¿—çº§åˆ«ä½¿ç”¨
def process_data(data: Dict) -> Dict:
    logger.debug(f"Processing data with {len(data)} items")
    
    try:
        # ä¿¡æ¯çº§æ—¥å¿—
        logger.info("Starting data processing")
        
        # å¤„ç†é€»è¾‘
        result = transform_data(data)
        
        # æˆåŠŸæ—¥å¿—
        logger.info(f"Successfully processed {len(result)} items")
        
        return result
        
    except ValueError as e:
        # è­¦å‘Šçº§æ—¥å¿—
        logger.warning(f"Invalid data format: {e}")
        return {}
        
    except Exception as e:
        # é”™è¯¯çº§æ—¥å¿—
        logger.error(f"Processing failed: {e}", exc_info=True)
        raise

# æ€§èƒ½æ—¥å¿—è£…é¥°å™¨
def log_performance(func):
    """è®°å½•å‡½æ•°æ‰§è¡Œæ—¶é—´çš„è£…é¥°å™¨"""
    @wraps(func)
    def wrapper(*args, **kwargs):
        start_time = time.perf_counter()
        logger.debug(f"Starting {func.__name__}")
        
        try:
            result = func(*args, **kwargs)
            elapsed = time.perf_counter() - start_time
            logger.info(f"{func.__name__} completed in {elapsed:.2f}s")
            return result
            
        except Exception as e:
            elapsed = time.perf_counter() - start_time
            logger.error(f"{func.__name__} failed after {elapsed:.2f}s: {e}")
            raise
    
    return wrapper

@log_performance
def expensive_operation():
    """è€—æ—¶æ“ä½œ"""
    time.sleep(2)
    return "Done"

# ç»“æ„åŒ–æ—¥å¿—
def log_structured(event: str, **kwargs):
    """ç»“æ„åŒ–æ—¥å¿—è®°å½•"""
    import json
    log_entry = {
        "event": event,
        "timestamp": time.time(),
        **kwargs
    }
    logger.info(json.dumps(log_entry))

# ä½¿ç”¨ç»“æ„åŒ–æ—¥å¿—
log_structured(
    "image_processed",
    image_path="/path/to/image.jpg",
    category="electronic",
    confidence=0.95,
    processing_time=0.234
)
```

### æµ‹è¯•è§„èŒƒ
```python
import pytest
from unittest.mock import Mock, patch, MagicMock
from pathlib import Path
import tempfile

# 1. æµ‹è¯•æ–‡ä»¶ç»„ç»‡
# test_<module_name>.py å¯¹åº” <module_name>.py

# 2. æµ‹è¯•ç±»å’Œå‡½æ•°å‘½å
class TestImageDetector:
    """æµ‹è¯•ImageDetectorç±»"""
    
    def test_initialization(self):
        """æµ‹è¯•åˆå§‹åŒ–"""
        detector = ImageDetector()
        assert detector is not None
    
    def test_detect_valid_image(self):
        """æµ‹è¯•æ£€æµ‹æœ‰æ•ˆå›¾åƒ"""
        detector = ImageDetector()
        result = detector.detect("test.jpg")
        assert result["status"] == "success"
    
    def test_detect_invalid_image(self):
        """æµ‹è¯•æ£€æµ‹æ— æ•ˆå›¾åƒ"""
        detector = ImageDetector()
        with pytest.raises(ImageNotFoundError):
            detector.detect("nonexistent.jpg")

# 3. ä½¿ç”¨fixtures
@pytest.fixture
def temp_image_file():
    """åˆ›å»ºä¸´æ—¶å›¾åƒæ–‡ä»¶çš„fixture"""
    with tempfile.NamedTemporaryFile(suffix='.jpg', delete=False) as f:
        # åˆ›å»ºæµ‹è¯•å›¾åƒ
        f.write(b"fake image data")
        temp_path = Path(f.name)
    
    yield temp_path
    
    # æ¸…ç†
    temp_path.unlink()

@pytest.fixture
def mock_detector():
    """åˆ›å»ºæ¨¡æ‹Ÿæ£€æµ‹å™¨çš„fixture"""
    detector = Mock(spec=ImageDetector)
    detector.detect.return_value = {
        "category": "electronic",
        "confidence": 0.95
    }
    return detector

# 4. å‚æ•°åŒ–æµ‹è¯•
@pytest.mark.parametrize("input_value,expected", [
    ("", False),
    ("valid", True),
    (None, False),
    ("test@example.com", True),
])
def test_validate_input(input_value, expected):
    """å‚æ•°åŒ–æµ‹è¯•éªŒè¯è¾“å…¥"""
    result = validate_input(input_value)
    assert result == expected

# 5. æµ‹è¯•å¼‚æ­¥å‡½æ•°
@pytest.mark.asyncio
async def test_async_fetch():
    """æµ‹è¯•å¼‚æ­¥è·å–å‡½æ•°"""
    async with aiohttp.ClientSession() as session:
        data = await fetch_data("https://api.example.com/data")
        assert data is not None

# 6. æµ‹è¯•å¼‚å¸¸
def test_division_by_zero():
    """æµ‹è¯•é™¤é›¶å¼‚å¸¸"""
    with pytest.raises(ZeroDivisionError):
        result = divide(10, 0)

# 7. Mockå¤–éƒ¨ä¾èµ–
@patch('src.core.detector.load_model')
def test_detector_with_mock_model(mock_load_model):
    """ä½¿ç”¨mockæµ‹è¯•æ£€æµ‹å™¨"""
    # è®¾ç½®mockè¿”å›å€¼
    mock_model = MagicMock()
    mock_model.predict.return_value = {"category": "test"}
    mock_load_model.return_value = mock_model
    
    # æµ‹è¯•
    detector = ImageDetector()
    result = detector.detect("test.jpg")
    
    # éªŒè¯
    assert result["category"] == "test"
    mock_load_model.assert_called_once()
    mock_model.predict.assert_called_once()

# 8. æ€§èƒ½æµ‹è¯•
@pytest.mark.benchmark
def test_performance(benchmark):
    """æ€§èƒ½åŸºå‡†æµ‹è¯•"""
    def process():
        return expensive_operation()
    
    result = benchmark(process)
    assert result is not None
    
    # æ£€æŸ¥æ€§èƒ½æŒ‡æ ‡
    assert benchmark.stats["mean"] < 1.0  # å¹³å‡æ—¶é—´å°äº1ç§’

# 9. é›†æˆæµ‹è¯•
@pytest.mark.integration
class TestAPIIntegration:
    """APIé›†æˆæµ‹è¯•"""
    
    @pytest.fixture(autouse=True)
    def setup(self):
        """æµ‹è¯•è®¾ç½®"""
        self.client = TestClient(app)
        
    def test_full_workflow(self):
        """æµ‹è¯•å®Œæ•´å·¥ä½œæµ"""
        # 1. ä¸Šä¼ å›¾åƒ
        response = self.client.post("/upload", files={"file": ("test.jpg", b"data")})
        assert response.status_code == 200
        photo_id = response.json()["id"]
        
        # 2. è·å–æ£€æµ‹ç»“æœ
        response = self.client.get(f"/photos/{photo_id}")
        assert response.status_code == 200
        assert response.json()["category"] is not None
        
        # 3. æœç´¢
        response = self.client.get("/search?q=test")
        assert response.status_code == 200
        assert len(response.json()["results"]) > 0
```

### FastAPIè§„èŒƒ
```python
from fastapi import FastAPI, HTTPException, Depends, Query, Path, Body, File, UploadFile
from fastapi.responses import JSONResponse
from fastapi.middleware.cors import CORSMiddleware
from pydantic import BaseModel, Field, validator
from typing import List, Optional
from datetime import datetime
import asyncio

# åˆ›å»ºåº”ç”¨
app = FastAPI(
    title="Vibe Photos API",
    description="AIæ™ºèƒ½ç…§ç‰‡ç®¡ç†ç³»ç»ŸAPI",
    version="1.0.0",
    docs_url="/docs",
    redoc_url="/redoc"
)

# é…ç½®CORS
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# Pydanticæ¨¡å‹
class PhotoBase(BaseModel):
    """ç…§ç‰‡åŸºç¡€æ¨¡å‹"""
    path: str = Field(..., description="ç…§ç‰‡è·¯å¾„")
    category: Optional[str] = Field(None, description="åˆ†ç±»")
    
    class Config:
        schema_extra = {
            "example": {
                "path": "/photos/IMG_001.jpg",
                "category": "electronic"
            }
        }

class PhotoCreate(PhotoBase):
    """åˆ›å»ºç…§ç‰‡æ¨¡å‹"""
    pass

class PhotoResponse(PhotoBase):
    """ç…§ç‰‡å“åº”æ¨¡å‹"""
    id: int
    confidence: float
    created_at: datetime
    
    class Config:
        orm_mode = True

class SearchQuery(BaseModel):
    """æœç´¢æŸ¥è¯¢æ¨¡å‹"""
    q: str = Field(..., min_length=1, max_length=100, description="æœç´¢å…³é”®è¯")
    limit: int = Field(20, ge=1, le=100, description="ç»“æœé™åˆ¶")
    category: Optional[str] = Field(None, description="åˆ†ç±»è¿‡æ»¤")
    
    @validator('q')
    def validate_query(cls, v):
        if not v.strip():
            raise ValueError("Query cannot be empty")
        return v.strip()

# ä¾èµ–æ³¨å…¥
async def get_db_session():
    """è·å–æ•°æ®åº“ä¼šè¯"""
    session = SessionLocal()
    try:
        yield session
    finally:
        session.close()

async def get_current_user(token: str = Depends(oauth2_scheme)):
    """è·å–å½“å‰ç”¨æˆ·"""
    # éªŒè¯token
    user = verify_token(token)
    if not user:
        raise HTTPException(status_code=401, detail="Invalid token")
    return user

# è·¯ç”±å®šä¹‰
@app.get("/", response_model=Dict[str, str])
async def root():
    """APIæ ¹è·¯å¾„"""
    return {
        "name": "Vibe Photos API",
        "version": "1.0.0",
        "status": "running"
    }

@app.post("/photos", response_model=PhotoResponse)
async def create_photo(
    photo: PhotoCreate,
    db: Session = Depends(get_db_session),
    current_user: User = Depends(get_current_user)
):
    """åˆ›å»ºç…§ç‰‡è®°å½•"""
    db_photo = Photo(**photo.dict())
    db.add(db_photo)
    db.commit()
    db.refresh(db_photo)
    return db_photo

@app.get("/photos/{photo_id}", response_model=PhotoResponse)
async def get_photo(
    photo_id: int = Path(..., gt=0, description="ç…§ç‰‡ID"),
    db: Session = Depends(get_db_session)
):
    """è·å–å•å¼ ç…§ç‰‡"""
    photo = db.query(Photo).filter(Photo.id == photo_id).first()
    if not photo:
        raise HTTPException(status_code=404, detail="Photo not found")
    return photo

@app.get("/search", response_model=List[PhotoResponse])
async def search_photos(
    query: SearchQuery = Depends(),
    db: Session = Depends(get_db_session)
):
    """æœç´¢ç…§ç‰‡"""
    photos = db.query(Photo).filter(
        Photo.caption.contains(query.q)
    ).limit(query.limit).all()
    return photos

@app.post("/upload")
async def upload_file(
    file: UploadFile = File(...),
    background_tasks: BackgroundTasks
):
    """ä¸Šä¼ æ–‡ä»¶"""
    # éªŒè¯æ–‡ä»¶ç±»å‹
    if not file.content_type.startswith("image/"):
        raise HTTPException(status_code=400, detail="File must be an image")
    
    # ä¿å­˜æ–‡ä»¶
    file_path = save_uploaded_file(file)
    
    # æ·»åŠ åå°ä»»åŠ¡
    background_tasks.add_task(process_image, file_path)
    
    return {"filename": file.filename, "status": "processing"}

# å¼‚å¸¸å¤„ç†
@app.exception_handler(ValueError)
async def value_error_handler(request, exc):
    """å¤„ç†å€¼é”™è¯¯"""
    return JSONResponse(
        status_code=400,
        content={"error": str(exc)}
    )

@app.exception_handler(404)
async def not_found_handler(request, exc):
    """å¤„ç†404é”™è¯¯"""
    return JSONResponse(
        status_code=404,
        content={"error": "Resource not found"}
    )

# ä¸­é—´ä»¶
@app.middleware("http")
async def log_requests(request, call_next):
    """è®°å½•è¯·æ±‚æ—¥å¿—"""
    start_time = time.time()
    
    response = await call_next(request)
    
    process_time = time.time() - start_time
    logger.info(f"{request.method} {request.url.path} - {process_time:.2f}s")
    
    response.headers["X-Process-Time"] = str(process_time)
    return response

# å¯åŠ¨å’Œå…³é—­äº‹ä»¶
@app.on_event("startup")
async def startup_event():
    """åº”ç”¨å¯åŠ¨äº‹ä»¶"""
    logger.info("Application starting up...")
    # åˆå§‹åŒ–æ•°æ®åº“è¿æ¥
    # åŠ è½½æ¨¡å‹
    # é¢„çƒ­ç¼“å­˜

@app.on_event("shutdown")
async def shutdown_event():
    """åº”ç”¨å…³é—­äº‹ä»¶"""
    logger.info("Application shutting down...")
    # å…³é—­æ•°æ®åº“è¿æ¥
    # æ¸…ç†èµ„æº
```

## ğŸ“‹ ä»£ç å®¡æŸ¥æ¸…å•

### åŠŸèƒ½æ€§æ£€æŸ¥
- [ ] ä»£ç æ˜¯å¦å®ç°äº†é¢„æœŸåŠŸèƒ½ï¼Ÿ
- [ ] è¾¹ç•Œæƒ…å†µæ˜¯å¦å¤„ç†ï¼Ÿ
- [ ] é”™è¯¯æƒ…å†µæ˜¯å¦å¦¥å–„å¤„ç†ï¼Ÿ
- [ ] æ˜¯å¦æœ‰æœªä½¿ç”¨çš„ä»£ç ï¼Ÿ

### ä»£ç è´¨é‡æ£€æŸ¥
- [ ] å‘½åæ˜¯å¦æ¸…æ™°æè¿°æ€§ï¼Ÿ
- [ ] å‡½æ•°æ˜¯å¦éµå¾ªå•ä¸€èŒè´£åŸåˆ™ï¼Ÿ
- [ ] æ˜¯å¦æœ‰é‡å¤ä»£ç å¯ä»¥æŠ½å–ï¼Ÿ
- [ ] å¤æ‚åº¦æ˜¯å¦å¯ä»¥é™ä½ï¼Ÿ

### ç±»å‹å’Œæ–‡æ¡£æ£€æŸ¥
- [ ] ç±»å‹æ³¨è§£æ˜¯å¦å®Œæ•´ï¼Ÿ
- [ ] æ–‡æ¡£å­—ç¬¦ä¸²æ˜¯å¦æ¸…æ™°ï¼Ÿ
- [ ] æ³¨é‡Šæ˜¯å¦å¿…è¦ä¸”æœ‰ç”¨ï¼Ÿ
- [ ] READMEæ˜¯å¦æ›´æ–°ï¼Ÿ

### æµ‹è¯•æ£€æŸ¥
- [ ] æ˜¯å¦æœ‰å¯¹åº”çš„æµ‹è¯•ï¼Ÿ
- [ ] æµ‹è¯•è¦†ç›–ç‡æ˜¯å¦è¶³å¤Ÿï¼Ÿ
- [ ] æµ‹è¯•æ˜¯å¦å¯ä»¥ç‹¬ç«‹è¿è¡Œï¼Ÿ
- [ ] æ˜¯å¦æœ‰é›†æˆæµ‹è¯•ï¼Ÿ

### æ€§èƒ½å’Œå®‰å…¨æ£€æŸ¥
- [ ] æ˜¯å¦æœ‰æ€§èƒ½ç“¶é¢ˆï¼Ÿ
- [ ] æ˜¯å¦æœ‰å†…å­˜æ³„æ¼é£é™©ï¼Ÿ
- [ ] æ˜¯å¦æœ‰SQLæ³¨å…¥é£é™©ï¼Ÿ
- [ ] æ•æ„Ÿä¿¡æ¯æ˜¯å¦å®‰å…¨å¤„ç†ï¼Ÿ

## ğŸš€ æ€§èƒ½ä¼˜åŒ–æŒ‡å—

### ä»£ç å±‚ä¼˜åŒ–
```python
# 1. ä½¿ç”¨ç”Ÿæˆå™¨é¿å…å†…å­˜å ç”¨
# âŒ ä¸å¥½ - ä¸€æ¬¡æ€§åŠ è½½æ‰€æœ‰æ•°æ®
def load_all_images(directory: Path) -> List[Image]:
    images = []
    for img_path in directory.glob("*.jpg"):
        images.append(load_image(img_path))
    return images

# âœ… å¥½ - ä½¿ç”¨ç”Ÿæˆå™¨å»¶è¿ŸåŠ è½½
def load_images_generator(directory: Path):
    for img_path in directory.glob("*.jpg"):
        yield load_image(img_path)

# 2. ç¼“å­˜é‡å¤è®¡ç®—
from functools import lru_cache

@lru_cache(maxsize=128)
def expensive_computation(param: str) -> Dict:
    """ç¼“å­˜æ˜‚è´µçš„è®¡ç®—ç»“æœ"""
    # å¤æ‚è®¡ç®—
    return result

# 3. æ‰¹å¤„ç†ä¼˜åŒ–
def process_batch(items: List, batch_size: int = 32):
    """æ‰¹å¤„ç†ä»¥æé«˜æ•ˆç‡"""
    for i in range(0, len(items), batch_size):
        batch = items[i:i + batch_size]
        # æ‰¹é‡å¤„ç†
        yield process_items(batch)

# 4. ä½¿ç”¨numpyå‘é‡åŒ–æ“ä½œ
import numpy as np

# âŒ ä¸å¥½ - Pythonå¾ªç¯
def compute_similarity_slow(vec1: List, vec2: List) -> float:
    result = 0
    for i in range(len(vec1)):
        result += vec1[i] * vec2[i]
    return result

# âœ… å¥½ - NumPyå‘é‡åŒ–
def compute_similarity_fast(vec1: np.ndarray, vec2: np.ndarray) -> float:
    return np.dot(vec1, vec2)

# 5. è¿æ¥æ± å¤ç”¨
from sqlalchemy.pool import QueuePool

engine = create_engine(
    "postgresql://...",
    poolclass=QueuePool,
    pool_size=20,
    max_overflow=0,
    pool_pre_ping=True
)
```

### å¼‚æ­¥ä¼˜åŒ–
```python
# å¹¶å‘å¤„ç†å¤šä¸ªä»»åŠ¡
async def process_images_concurrent(image_paths: List[Path]):
    """å¹¶å‘å¤„ç†å¤šä¸ªå›¾åƒ"""
    tasks = []
    for path in image_paths:
        task = asyncio.create_task(process_image_async(path))
        tasks.append(task)
    
    results = await asyncio.gather(*tasks)
    return results

# é™åˆ¶å¹¶å‘æ•°
async def process_with_semaphore(items: List, max_concurrent: int = 10):
    """ä½¿ç”¨ä¿¡å·é‡é™åˆ¶å¹¶å‘æ•°"""
    semaphore = asyncio.Semaphore(max_concurrent)
    
    async def process_item(item):
        async with semaphore:
            return await process_async(item)
    
    tasks = [process_item(item) for item in items]
    return await asyncio.gather(*tasks)
```

## ğŸ” è°ƒè¯•æŠ€å·§

### ä½¿ç”¨è°ƒè¯•å·¥å…·
```python
# 1. ä½¿ç”¨pdbè°ƒè¯•
import pdb

def complex_function(data):
    processed = preprocess(data)
    pdb.set_trace()  # æ–­ç‚¹
    result = transform(processed)
    return result

# 2. ä½¿ç”¨loggingè°ƒè¯•
import logging
logging.basicConfig(level=logging.DEBUG)

def debug_function(data):
    logger.debug(f"Input data: {data}")
    result = process(data)
    logger.debug(f"Output result: {result}")
    return result

# 3. ä½¿ç”¨è£…é¥°å™¨è¿½è¸ª
def trace(func):
    """è¿½è¸ªå‡½æ•°è°ƒç”¨çš„è£…é¥°å™¨"""
    def wrapper(*args, **kwargs):
        print(f"Calling {func.__name__} with args={args}, kwargs={kwargs}")
        result = func(*args, **kwargs)
        print(f"{func.__name__} returned {result}")
        return result
    return wrapper

@trace
def calculate(a, b):
    return a + b

# 4. æ€§èƒ½åˆ†æ
import cProfile
import pstats

def profile_function():
    profiler = cProfile.Profile()
    profiler.enable()
    
    # è¦åˆ†æçš„ä»£ç 
    expensive_operation()
    
    profiler.disable()
    stats = pstats.Stats(profiler)
    stats.sort_stats('cumulative')
    stats.print_stats(10)
```

## ğŸ“ Gitæäº¤è§„èŒƒ

### æäº¤æ¶ˆæ¯æ ¼å¼
```
<type>(<scope>): <subject>

<body>

<footer>
```

### ç±»å‹ï¼ˆtypeï¼‰
- `feat`: æ–°åŠŸèƒ½
- `fix`: Bugä¿®å¤
- `docs`: æ–‡æ¡£æ›´æ–°
- `style`: ä»£ç æ ¼å¼ï¼ˆä¸å½±å“åŠŸèƒ½ï¼‰
- `refactor`: é‡æ„
- `perf`: æ€§èƒ½ä¼˜åŒ–
- `test`: æµ‹è¯•ç›¸å…³
- `chore`: æ„å»º/å·¥å…·é“¾ç›¸å…³

### ç¤ºä¾‹
```bash
# å¥½çš„æäº¤æ¶ˆæ¯
git commit -m "feat(detector): add SigLIP model support for multi-language classification"
git commit -m "fix(api): handle null values in search query"
git commit -m "docs(readme): update installation instructions"
git commit -m "perf(processor): optimize batch processing with parallel execution"

# ä¸å¥½çš„æäº¤æ¶ˆæ¯
git commit -m "update"
git commit -m "fix bug"
git commit -m "changes"
```

## ğŸ¯ ä»£ç è´¨é‡ç›®æ ‡

### å¿…é¡»è¾¾åˆ°çš„æŒ‡æ ‡
- **æµ‹è¯•è¦†ç›–ç‡**: â‰¥ 80%
- **ä»£ç å¤æ‚åº¦**: åœˆå¤æ‚åº¦ < 10
- **å‡½æ•°é•¿åº¦**: < 50è¡Œ
- **ç±»é•¿åº¦**: < 300è¡Œ
- **æ–‡ä»¶é•¿åº¦**: < 500è¡Œ
- **å“åº”æ—¶é—´**: P95 < 500ms
- **é”™è¯¯ç‡**: < 1%

### ä»£ç è´¨é‡å·¥å…·é…ç½®
```yaml
# .ruff.toml
line-length = 100
target-version = "py312"

[lint]
select = ["E", "F", "I", "N", "W", "UP", "ASYNC", "B", "A", "C4", "DTZ", "T10", "EM", "ISC", "ICN", "T20", "Q", "RET", "SIM", "TID", "ARG", "ERA", "PD", "PGH", "PL", "TRY", "NPY", "RUF"]
ignore = ["E501"]

# pytest.ini
[tool.pytest.ini_options]
minversion = "6.0"
testpaths = ["tests"]
python_files = "test_*.py"
python_classes = "Test*"
python_functions = "test_*"
addopts = "-ra -q --strict-markers --cov=src --cov-report=term-missing"

# mypy.ini
[mypy]
python_version = "3.12"
warn_return_any = true
warn_unused_configs = true
disallow_untyped_defs = true
disallow_any_unimported = true
no_implicit_optional = true
warn_redundant_casts = true
warn_unused_ignores = true
warn_no_return = true
check_untyped_defs = true
```

---

**æ–‡æ¡£ç‰ˆæœ¬**: 1.0.0
**æœ€åæ›´æ–°**: 2024-11-12
**é€‚ç”¨äº**: Python 3.12 + FastAPI + uv
**ç›®æ ‡**: ä¿è¯ä»£ç è´¨é‡å’Œä¸€è‡´æ€§
