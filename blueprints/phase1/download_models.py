#!/usr/bin/env python3
"""
æ¨¡å‹é¢„ä¸‹è½½è„šæœ¬ - Phase 1

é¢„ä¸‹è½½æ‰€æœ‰å¿…éœ€çš„æ¨¡å‹æ–‡ä»¶åˆ° models/ ç›®å½•ï¼Œé¿å…è¿è¡Œæ—¶ä¸‹è½½ã€‚
æ”¯æŒæ–­ç‚¹ç»­ä¼ å’Œå®Œæ•´æ€§æ ¡éªŒã€‚
"""

import os
import sys
import hashlib
from pathlib import Path
from typing import Dict, Optional
import requests
from tqdm import tqdm
import json
import time

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°è·¯å¾„
PROJECT_ROOT = Path(__file__).parent.parent.parent
sys.path.insert(0, str(PROJECT_ROOT))

# æ¨¡å‹å­˜å‚¨ç›®å½•
MODELS_DIR = PROJECT_ROOT / "models"
MODELS_DIR.mkdir(exist_ok=True)

# æ¨¡å‹é…ç½®
MODELS_CONFIG = {
    "rtmdet": {
        "name": "SigLIP+BLIP",
        "description": "å¤šè¯­è¨€å›¾åƒç†è§£æ¨¡å‹",
        "files": {
            "config": {
                "url": "https://download.openmmlab.com/mmdetection/v3.0/rtmdet/rtmdet_l_8xb32-300e_coco/rtmdet_l_8xb32-300e_coco.py",
                "size": "~10KB",
                "path": "rtmdet/rtmdet_l_coco.py"
            },
            "checkpoint": {
                "url": "https://download.openmmlab.com/mmdetection/v3.0/rtmdet/rtmdet_l_8xb32-300e_coco/rtmdet_l_8xb32-300e_coco_20220719_112030-5a0be7c4.pth",
                "size": "~330MB",
                "path": "rtmdet/rtmdet_l_coco.pth",
                "sha256": "5a0be7c4"  # ç®€åŒ–çš„hashï¼Œå®é™…ä½¿ç”¨æ—¶éœ€è¦å®Œæ•´hash
            }
        }
    },
    "paddleocr": {
        "name": "PaddleOCR",
        "description": "ä¸­è‹±æ–‡OCRæ¨¡å‹",
        "files": {
            "det_model": {
                "url": "https://paddleocr.bj.bcebos.com/PP-OCRv4/chinese/ch_PP-OCRv4_det_infer.tar",
                "size": "~4.9MB",
                "path": "paddleocr/ch_PP-OCRv4_det_infer.tar",
                "extract": True
            },
            "rec_model": {
                "url": "https://paddleocr.bj.bcebos.com/PP-OCRv4/chinese/ch_PP-OCRv4_rec_infer.tar",
                "size": "~10MB",
                "path": "paddleocr/ch_PP-OCRv4_rec_infer.tar",
                "extract": True
            },
            "cls_model": {
                "url": "https://paddleocr.bj.bcebos.com/dygraph_v2.0/ch/ch_ppocr_mobile_v2.0_cls_infer.tar",
                "size": "~2.1MB",
                "path": "paddleocr/ch_ppocr_mobile_v2.0_cls_infer.tar",
                "extract": True
            }
        }
    }
}

def download_file(url: str, dest_path: Path, desc: str, chunk_size: int = 8192) -> bool:
    """
    ä¸‹è½½æ–‡ä»¶ï¼Œæ”¯æŒæ–­ç‚¹ç»­ä¼ å’Œè¿›åº¦æ˜¾ç¤º
    
    Args:
        url: ä¸‹è½½URL
        dest_path: ç›®æ ‡æ–‡ä»¶è·¯å¾„
        desc: è¿›åº¦æ¡æè¿°
        chunk_size: ä¸‹è½½å—å¤§å°
    
    Returns:
        æ˜¯å¦ä¸‹è½½æˆåŠŸ
    """
    dest_path.parent.mkdir(parents=True, exist_ok=True)
    
    # æ£€æŸ¥æ˜¯å¦éœ€è¦æ–­ç‚¹ç»­ä¼ 
    resume_pos = 0
    mode = 'wb'
    if dest_path.exists():
        resume_pos = dest_path.stat().st_size
        mode = 'ab'
    
    try:
        # è®¾ç½®è¯·æ±‚å¤´
        headers = {}
        if resume_pos > 0:
            headers['Range'] = f'bytes={resume_pos}-'
            print(f"  ç»§ç»­ä¸‹è½½: {dest_path.name} (å·²ä¸‹è½½ {resume_pos:,} bytes)")
        
        response = requests.get(url, headers=headers, stream=True, timeout=30)
        response.raise_for_status()
        
        # è·å–æ–‡ä»¶æ€»å¤§å°
        total_size = int(response.headers.get('content-length', 0))
        if resume_pos > 0:
            total_size += resume_pos
        
        # å¦‚æœæ–‡ä»¶å·²å®Œæ•´ä¸‹è½½
        if resume_pos >= total_size and total_size > 0:
            print(f"  âœ“ {dest_path.name} å·²å­˜åœ¨ä¸”å®Œæ•´")
            return True
        
        # ä¸‹è½½æ–‡ä»¶
        with open(dest_path, mode) as f:
            with tqdm(
                total=total_size,
                initial=resume_pos,
                unit='iB',
                unit_scale=True,
                desc=desc,
                ncols=100
            ) as pbar:
                for chunk in response.iter_content(chunk_size=chunk_size):
                    if chunk:
                        f.write(chunk)
                        pbar.update(len(chunk))
        
        print(f"  âœ“ ä¸‹è½½å®Œæˆ: {dest_path.name}")
        return True
        
    except requests.exceptions.RequestException as e:
        print(f"  âœ— ä¸‹è½½å¤±è´¥: {e}")
        return False
    except KeyboardInterrupt:
        print("\n  ! ä¸‹è½½è¢«ä¸­æ–­ï¼Œä¸‹æ¬¡è¿è¡Œå°†ç»§ç»­")
        return False

def extract_tar(tar_path: Path) -> bool:
    """è§£å‹taræ–‡ä»¶"""
    import tarfile
    
    try:
        extract_dir = tar_path.parent
        print(f"  è§£å‹ä¸­: {tar_path.name}")
        
        with tarfile.open(tar_path, 'r') as tar:
            tar.extractall(extract_dir)
        
        print(f"  âœ“ è§£å‹å®Œæˆ: {extract_dir}")
        return True
        
    except Exception as e:
        print(f"  âœ— è§£å‹å¤±è´¥: {e}")
        return False

def verify_file(file_path: Path, expected_hash: Optional[str] = None) -> bool:
    """éªŒè¯æ–‡ä»¶å®Œæ•´æ€§"""
    if not file_path.exists():
        return False
    
    if expected_hash:
        # è®¡ç®—æ–‡ä»¶hashï¼ˆç®€åŒ–ç‰ˆï¼Œå®é™…éœ€è¦å®Œæ•´å®ç°ï¼‰
        print(f"  éªŒè¯ä¸­: {file_path.name}")
        # TODO: å®ç°å®Œæ•´çš„hashéªŒè¯
        return True
    
    # åŸºæœ¬æ£€æŸ¥ï¼šæ–‡ä»¶å¤§å°ä¸ä¸º0
    return file_path.stat().st_size > 0

def download_all_models() -> bool:
    """ä¸‹è½½æ‰€æœ‰æ¨¡å‹"""
    print("=" * 60)
    print("Phase 1 æ¨¡å‹é¢„ä¸‹è½½")
    print("=" * 60)
    print(f"æ¨¡å‹ç›®å½•: {MODELS_DIR}")
    print()
    
    all_success = True
    
    for model_key, model_info in MODELS_CONFIG.items():
        print(f"\nğŸ“¦ {model_info['name']}")
        print(f"   {model_info['description']}")
        print("-" * 40)
        
        for file_key, file_info in model_info['files'].items():
            dest_path = MODELS_DIR / file_info['path']
            
            # æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å·²å­˜åœ¨
            if dest_path.exists() and verify_file(dest_path, file_info.get('sha256')):
                print(f"  âœ“ {dest_path.name} å·²å­˜åœ¨")
                
                # å¦‚æœéœ€è¦è§£å‹ä¸”æœªè§£å‹
                if file_info.get('extract') and dest_path.suffix == '.tar':
                    extract_dir = dest_path.parent / dest_path.stem
                    if not extract_dir.exists():
                        extract_tar(dest_path)
                continue
            
            # ä¸‹è½½æ–‡ä»¶
            print(f"  ä¸‹è½½: {file_info['size']} - {file_key}")
            success = download_file(
                file_info['url'],
                dest_path,
                f"  {model_info['name']}/{file_key}"
            )
            
            if not success:
                all_success = False
                continue
            
            # è§£å‹æ–‡ä»¶ï¼ˆå¦‚æœéœ€è¦ï¼‰
            if file_info.get('extract') and dest_path.suffix == '.tar':
                extract_tar(dest_path)
    
    # åˆ›å»ºæ¨¡å‹ä¿¡æ¯æ–‡ä»¶
    info_file = MODELS_DIR / "models_info.json"
    with open(info_file, 'w', encoding='utf-8') as f:
        info = {
            "download_time": time.strftime("%Y-%m-%d %H:%M:%S"),
            "models": MODELS_CONFIG
        }
        json.dump(info, f, indent=2, ensure_ascii=False)
    
    print("\n" + "=" * 60)
    if all_success:
        print("âœ… æ‰€æœ‰æ¨¡å‹ä¸‹è½½å®Œæˆï¼")
        print(f"   æ¨¡å‹å­˜å‚¨åœ¨: {MODELS_DIR}")
        print("\n   ä¸‹ä¸€æ­¥ï¼š")
        print("   python process_dataset.py")
    else:
        print("âš ï¸  éƒ¨åˆ†æ¨¡å‹ä¸‹è½½å¤±è´¥")
        print("   è¯·é‡æ–°è¿è¡Œæ­¤è„šæœ¬ç»§ç»­ä¸‹è½½")
    print("=" * 60)
    
    return all_success

def clean_models():
    """æ¸…ç†æ‰€æœ‰å·²ä¸‹è½½çš„æ¨¡å‹"""
    print("æ¸…ç†æ¨¡å‹ç›®å½•...")
    import shutil
    
    if MODELS_DIR.exists():
        shutil.rmtree(MODELS_DIR)
        MODELS_DIR.mkdir(exist_ok=True)
        print(f"âœ“ å·²æ¸…ç†: {MODELS_DIR}")

if __name__ == "__main__":
    import argparse
    
    parser = argparse.ArgumentParser(description="Phase 1 æ¨¡å‹é¢„ä¸‹è½½å·¥å…·")
    parser.add_argument(
        "--clean",
        action="store_true",
        help="æ¸…ç†æ‰€æœ‰å·²ä¸‹è½½çš„æ¨¡å‹"
    )
    parser.add_argument(
        "--check",
        action="store_true",
        help="ä»…æ£€æŸ¥æ¨¡å‹æ˜¯å¦å·²ä¸‹è½½"
    )
    
    args = parser.parse_args()
    
    if args.clean:
        clean_models()
    elif args.check:
        # TODO: å®ç°æ£€æŸ¥åŠŸèƒ½
        print("æ£€æŸ¥åŠŸèƒ½å¾…å®ç°")
    else:
        success = download_all_models()
        sys.exit(0 if success else 1)
