#!/usr/bin/env python3
"""
æ··åˆè¯†åˆ«å™¨ POC - å±•ç¤ºAI+äººå·¥çš„ååŒå·¥ä½œæ¨¡å¼
æ¼”ç¤ºå¦‚ä½•å¹³è¡¡è‡ªåŠ¨åŒ–å’Œäººå·¥ä»‹å…¥
"""

from typing import Dict, List, Optional, Tuple
from dataclasses import dataclass, field
from enum import Enum
import json
from pathlib import Path
from datetime import datetime


class ConfidenceLevel(Enum):
    """ç½®ä¿¡åº¦çº§åˆ«"""
    HIGH = "high"        # > 0.8  - è‡ªåŠ¨å¤„ç†
    MEDIUM = "medium"    # 0.5-0.8 - AIå»ºè®®
    LOW = "low"          # < 0.5  - éœ€è¦äººå·¥


@dataclass
class RecognitionResult:
    """è¯†åˆ«ç»“æœ"""
    # åŸºç¡€ä¿¡æ¯
    image_path: str
    timestamp: str = field(default_factory=lambda: datetime.now().isoformat())
    
    # AIé¢„æµ‹
    ai_category: Optional[str] = None
    ai_confidence: Optional[float] = None
    ai_suggestions: List[Dict] = field(default_factory=list)
    
    # äººå·¥æ ‡æ³¨
    human_label: Optional[str] = None
    human_verified: bool = False
    
    # å†³ç­–ä¿¡æ¯
    confidence_level: Optional[ConfidenceLevel] = None
    action_taken: Optional[str] = None
    needs_review: bool = True
    
    # å­¦ä¹ ç›¸å…³
    used_for_training: bool = False
    similar_images: List[str] = field(default_factory=list)


class HybridRecognizer:
    """
    æ··åˆè¯†åˆ«å™¨ï¼šAI + äººå·¥çš„æœ€ä½³é…åˆ
    """
    
    def __init__(self):
        """åˆå§‹åŒ–è¯†åˆ«å™¨"""
        # æ¨¡æ‹Ÿçš„è¯†åˆ«é˜ˆå€¼
        self.thresholds = {
            'auto_accept': 0.8,     # è‡ªåŠ¨æ¥å—
            'suggest': 0.5,         # æä¾›å»ºè®®
            'reject': 0.3           # æ‹’ç»ï¼Œéœ€è¦äººå·¥
        }
        
        # æ¨¡æ‹Ÿçš„å·²å­¦ä¹ æ¨¡å¼
        self.learned_patterns = {}
        
        # æ ‡æ³¨å†å²ï¼ˆç”¨äºå­¦ä¹ ï¼‰
        self.annotation_history = []
        
        # ç”¨æˆ·åå¥½
        self.user_preferences = {
            'common_labels': ['iPhone', 'MacBook', 'æŠ«è¨', 'æˆªå›¾'],
            'recent_labels': [],
            'label_shortcuts': {
                '1': 'iPhone',
                '2': 'MacBook', 
                '3': 'æŠ«è¨',
                '4': 'æ–‡æ¡£'
            }
        }
    
    def recognize(self, image_path: str, 
                 ai_prediction: Tuple[str, float]) -> RecognitionResult:
        """
        æ‰§è¡Œæ··åˆè¯†åˆ«
        
        Args:
            image_path: å›¾åƒè·¯å¾„
            ai_prediction: AIé¢„æµ‹ç»“æœ (ç±»åˆ«, ç½®ä¿¡åº¦)
            
        Returns:
            è¯†åˆ«ç»“æœ
        """
        category, confidence = ai_prediction
        
        # åˆ›å»ºç»“æœå¯¹è±¡
        result = RecognitionResult(
            image_path=image_path,
            ai_category=category,
            ai_confidence=confidence
        )
        
        # åˆ¤æ–­ç½®ä¿¡åº¦çº§åˆ«
        result.confidence_level = self._get_confidence_level(confidence)
        
        # æ ¹æ®ç½®ä¿¡åº¦å†³å®šè¡ŒåŠ¨
        if result.confidence_level == ConfidenceLevel.HIGH:
            # é«˜ç½®ä¿¡åº¦ï¼šè‡ªåŠ¨æ¥å—
            result.action_taken = "auto_accepted"
            result.human_label = category
            result.needs_review = False
            result.human_verified = True
            print(f"âœ… è‡ªåŠ¨æ¥å—: {category} ({confidence:.1%})")
            
        elif result.confidence_level == ConfidenceLevel.MEDIUM:
            # ä¸­ç½®ä¿¡åº¦ï¼šæä¾›å»ºè®®
            result.action_taken = "suggested"
            result.ai_suggestions = self._generate_suggestions(image_path, category)
            result.needs_review = True
            print(f"ğŸ’¡ AIå»ºè®®: {category} ({confidence:.1%})")
            print(f"   å…¶ä»–å¯èƒ½: {result.ai_suggestions}")
            
        else:
            # ä½ç½®ä¿¡åº¦ï¼šéœ€è¦äººå·¥
            result.action_taken = "manual_required"
            result.needs_review = True
            print(f"â“ éœ€è¦äººå·¥æ ‡æ³¨ (AIçŒœæµ‹: {category} - {confidence:.1%})")
        
        # æŸ¥æ‰¾ç›¸ä¼¼å›¾ç‰‡
        result.similar_images = self._find_similar_images(image_path)
        if result.similar_images:
            print(f"ğŸ“· æ‰¾åˆ° {len(result.similar_images)} å¼ ç›¸ä¼¼å›¾ç‰‡")
        
        return result
    
    def apply_human_annotation(self, result: RecognitionResult, 
                              human_label: str) -> RecognitionResult:
        """
        åº”ç”¨äººå·¥æ ‡æ³¨
        
        Args:
            result: åŸå§‹è¯†åˆ«ç»“æœ
            human_label: äººå·¥æ ‡æ³¨
            
        Returns:
            æ›´æ–°åçš„ç»“æœ
        """
        result.human_label = human_label
        result.human_verified = True
        result.needs_review = False
        
        # è®°å½•æ ‡æ³¨å†å²
        self.annotation_history.append({
            'image': result.image_path,
            'ai_prediction': result.ai_category,
            'ai_confidence': result.ai_confidence,
            'human_label': human_label,
            'timestamp': result.timestamp
        })
        
        # æ›´æ–°ç”¨æˆ·åå¥½
        if human_label not in self.user_preferences['recent_labels']:
            self.user_preferences['recent_labels'].insert(0, human_label)
            self.user_preferences['recent_labels'] = \
                self.user_preferences['recent_labels'][:10]  # ä¿ç•™æœ€è¿‘10ä¸ª
        
        # å¦‚æœäººå·¥æ ‡æ³¨ä¸AIä¸åŒï¼Œæ ‡è®°ç”¨äºå­¦ä¹ 
        if human_label != result.ai_category:
            result.used_for_training = True
            self._learn_from_correction(result)
        
        print(f"âœï¸ äººå·¥æ ‡æ³¨: {human_label}")
        
        return result
    
    def batch_apply(self, primary_result: RecognitionResult, 
                   similar_images: List[str]) -> List[RecognitionResult]:
        """
        æ‰¹é‡åº”ç”¨æ ‡æ³¨åˆ°ç›¸ä¼¼å›¾ç‰‡
        
        Args:
            primary_result: ä¸»å›¾ç‰‡çš„ç»“æœ
            similar_images: ç›¸ä¼¼å›¾ç‰‡åˆ—è¡¨
            
        Returns:
            æ‰¹é‡å¤„ç†ç»“æœ
        """
        if not primary_result.human_verified:
            print("âš ï¸ ä¸»å›¾ç‰‡æœªç»äººå·¥ç¡®è®¤ï¼Œæ— æ³•æ‰¹é‡åº”ç”¨")
            return []
        
        results = []
        for img_path in similar_images:
            # åˆ›å»ºæ–°ç»“æœ
            batch_result = RecognitionResult(
                image_path=img_path,
                ai_category=primary_result.ai_category,
                ai_confidence=0.95,  # åŸºäºç›¸ä¼¼æ€§çš„é«˜ç½®ä¿¡åº¦
                human_label=primary_result.human_label,
                human_verified=True,
                needs_review=False,
                action_taken="batch_applied"
            )
            results.append(batch_result)
        
        print(f"ğŸ¯ æ‰¹é‡åº”ç”¨æ ‡ç­¾ '{primary_result.human_label}' åˆ° {len(results)} å¼ å›¾ç‰‡")
        
        return results
    
    def generate_annotation_ui(self, result: RecognitionResult) -> Dict:
        """
        ç”Ÿæˆæ ‡æ³¨ç•Œé¢æ•°æ®
        
        æ¨¡æ‹Ÿä¸€ä¸ªæ™ºèƒ½çš„æ ‡æ³¨ç•Œé¢
        """
        ui_data = {
            'image': result.image_path,
            'ai_prediction': {
                'category': result.ai_category,
                'confidence': result.ai_confidence,
                'level': result.confidence_level.value if result.confidence_level else None
            },
            'suggestions': [],
            'shortcuts': self.user_preferences['label_shortcuts'],
            'recent_labels': self.user_preferences['recent_labels'],
            'similar_count': len(result.similar_images),
            'actions': []
        }
        
        # æ ¹æ®ç½®ä¿¡åº¦ç”Ÿæˆä¸åŒçš„UI
        if result.confidence_level == ConfidenceLevel.HIGH:
            ui_data['actions'] = [
                {'key': 'Space', 'action': 'ç¡®è®¤', 'primary': True},
                {'key': 'X', 'action': 'è·³è¿‡'},
                {'key': 'E', 'action': 'ç¼–è¾‘'}
            ]
            ui_data['message'] = f"AIé«˜åº¦ç¡®ä¿¡è¿™æ˜¯: {result.ai_category}"
            
        elif result.confidence_level == ConfidenceLevel.MEDIUM:
            # æä¾›å¤šä¸ªé€‰é¡¹
            ui_data['suggestions'] = [
                result.ai_category,
                *[s['label'] for s in result.ai_suggestions[:3]]
            ]
            ui_data['actions'] = [
                {'key': '1-4', 'action': 'é€‰æ‹©å»ºè®®'},
                {'key': 'T', 'action': 'è¾“å…¥è‡ªå®šä¹‰'},
                {'key': 'X', 'action': 'è·³è¿‡'}
            ]
            ui_data['message'] = "AIä¸å¤ªç¡®å®šï¼Œè¯·é€‰æ‹©æˆ–è¾“å…¥"
            
        else:
            ui_data['actions'] = [
                {'key': '1-9', 'action': 'å¿«æ·æ ‡ç­¾'},
                {'key': 'T', 'action': 'è¾“å…¥æ ‡ç­¾'},
                {'key': 'X', 'action': 'æ ‡è®°ä¸ºæœªçŸ¥'}
            ]
            ui_data['message'] = "AIæ— æ³•è¯†åˆ«ï¼Œè¯·æ‰‹åŠ¨æ ‡æ³¨"
        
        # æ·»åŠ æ‰¹é‡æ“ä½œé€‰é¡¹
        if result.similar_images:
            ui_data['batch_option'] = {
                'available': True,
                'count': len(result.similar_images),
                'key': 'G',
                'action': 'åº”ç”¨åˆ°æ‰€æœ‰ç›¸ä¼¼å›¾ç‰‡'
            }
        
        return ui_data
    
    def _get_confidence_level(self, confidence: float) -> ConfidenceLevel:
        """åˆ¤æ–­ç½®ä¿¡åº¦çº§åˆ«"""
        if confidence >= self.thresholds['auto_accept']:
            return ConfidenceLevel.HIGH
        elif confidence >= self.thresholds['suggest']:
            return ConfidenceLevel.MEDIUM
        else:
            return ConfidenceLevel.LOW
    
    def _generate_suggestions(self, image_path: str, 
                            primary_category: str) -> List[Dict]:
        """ç”Ÿæˆå¤‡é€‰å»ºè®®"""
        # æ¨¡æ‹Ÿç”Ÿæˆå»ºè®®
        suggestions = []
        
        # åŸºäºå†å²çš„å»ºè®®
        if self.user_preferences['recent_labels']:
            suggestions.append({
                'label': self.user_preferences['recent_labels'][0],
                'reason': 'recently_used',
                'score': 0.7
            })
        
        # åŸºäºç›¸ä¼¼æ€§çš„å»ºè®®
        similar_categories = {
            'æ‰‹æœº': ['iPhone', 'Samsung', 'Androidæ‰‹æœº'],
            'ç”µè„‘': ['MacBook', 'ThinkPad', 'ç¬”è®°æœ¬'],
            'ç¾é£Ÿ': ['æŠ«è¨', 'æ±‰å ¡', 'é¢æ¡']
        }
        
        if primary_category in similar_categories:
            for cat in similar_categories[primary_category][:2]:
                suggestions.append({
                    'label': cat,
                    'reason': 'similar_category',
                    'score': 0.6
                })
        
        return suggestions
    
    def _find_similar_images(self, image_path: str) -> List[str]:
        """æŸ¥æ‰¾ç›¸ä¼¼å›¾ç‰‡"""
        # æ¨¡æ‹ŸæŸ¥æ‰¾ç›¸ä¼¼å›¾ç‰‡
        # å®é™…å®ç°ä¸­ä¼šä½¿ç”¨å‘é‡ç›¸ä¼¼åº¦
        import random
        
        if random.random() > 0.5:
            count = random.randint(1, 10)
            return [f"similar_{i}.jpg" for i in range(count)]
        return []
    
    def _learn_from_correction(self, result: RecognitionResult):
        """ä»çº æ­£ä¸­å­¦ä¹ """
        # æ¨¡æ‹Ÿå­¦ä¹ è¿‡ç¨‹
        key = f"{result.ai_category}->{result.human_label}"
        
        if key not in self.learned_patterns:
            self.learned_patterns[key] = 0
        self.learned_patterns[key] += 1
        
        print(f"ğŸ§  å­¦ä¹ æ¨¡å¼: {key} (å·²è§{self.learned_patterns[key]}æ¬¡)")
        
        # å¦‚æœæŸä¸ªæ¨¡å¼å‡ºç°å¤šæ¬¡ï¼Œå¯ä»¥è°ƒæ•´é˜ˆå€¼æˆ–æ·»åŠ è§„åˆ™
        if self.learned_patterns[key] >= 5:
            print(f"ğŸ’¡ æ£€æµ‹åˆ°é¢‘ç¹çº æ­£æ¨¡å¼ï¼Œå»ºè®®é‡æ–°è®­ç»ƒæ¨¡å‹")
    
    def get_statistics(self) -> Dict:
        """è·å–ç»Ÿè®¡ä¿¡æ¯"""
        total = len(self.annotation_history)
        
        if total == 0:
            return {'message': 'æš‚æ— æ ‡æ³¨å†å²'}
        
        correct = sum(1 for a in self.annotation_history 
                     if a['ai_prediction'] == a['human_label'])
        
        accuracy = correct / total if total > 0 else 0
        
        return {
            'total_annotations': total,
            'ai_correct': correct,
            'ai_accuracy': accuracy,
            'learned_patterns': len(self.learned_patterns),
            'common_corrections': sorted(
                self.learned_patterns.items(), 
                key=lambda x: x[1], 
                reverse=True
            )[:5]
        }


def demo():
    """æ¼”ç¤ºæ··åˆè¯†åˆ«æµç¨‹"""
    
    print("=== æ··åˆè¯†åˆ«å™¨æ¼”ç¤º ===\n")
    
    recognizer = HybridRecognizer()
    
    # æ¨¡æ‹Ÿä¸åŒç½®ä¿¡åº¦çš„åœºæ™¯
    test_cases = [
        ("photo1.jpg", ("iPhone", 0.92)),      # é«˜ç½®ä¿¡åº¦
        ("photo2.jpg", ("æ‰‹æœº", 0.65)),        # ä¸­ç½®ä¿¡åº¦
        ("photo3.jpg", ("æœªçŸ¥ç‰©ä½“", 0.25)),    # ä½ç½®ä¿¡åº¦
        ("photo4.jpg", ("MacBook", 0.88)),     # é«˜ç½®ä¿¡åº¦
        ("photo5.jpg", ("ç”µè„‘", 0.55)),        # ä¸­ç½®ä¿¡åº¦
    ]
    
    results = []
    
    for image_path, ai_prediction in test_cases:
        print(f"\n--- å¤„ç†: {image_path} ---")
        
        # æ‰§è¡Œè¯†åˆ«
        result = recognizer.recognize(image_path, ai_prediction)
        
        # å¦‚æœéœ€è¦äººå·¥ä»‹å…¥ï¼Œæ¨¡æ‹Ÿæ ‡æ³¨
        if result.needs_review:
            # ç”ŸæˆUIæ•°æ®
            ui_data = recognizer.generate_annotation_ui(result)
            print(f"UIæç¤º: {ui_data['message']}")
            
            # æ¨¡æ‹Ÿäººå·¥æ ‡æ³¨
            if result.confidence_level == ConfidenceLevel.MEDIUM:
                # ä¸­ç½®ä¿¡åº¦ï¼Œç¡®è®¤AIçš„å»ºè®®
                human_label = result.ai_category
            else:
                # ä½ç½®ä¿¡åº¦ï¼Œæä¾›æ–°æ ‡ç­¾
                human_label = "ä¸“ä¸šè®¾å¤‡"
            
            result = recognizer.apply_human_annotation(result, human_label)
            
            # å¦‚æœæœ‰ç›¸ä¼¼å›¾ç‰‡ï¼Œæ‰¹é‡åº”ç”¨
            if result.similar_images:
                batch_results = recognizer.batch_apply(result, result.similar_images)
                results.extend(batch_results)
        
        results.append(result)
    
    # æ˜¾ç¤ºç»Ÿè®¡
    print("\n=== ç»Ÿè®¡ä¿¡æ¯ ===")
    stats = recognizer.get_statistics()
    print(json.dumps(stats, indent=2, ensure_ascii=False))
    
    # ä¿å­˜ç»“æœ
    output = {
        'results': [
            {
                'image': r.image_path,
                'ai_category': r.ai_category,
                'ai_confidence': r.ai_confidence,
                'human_label': r.human_label,
                'action': r.action_taken,
                'verified': r.human_verified
            }
            for r in results
        ],
        'statistics': stats
    }
    
    with open('hybrid_recognition_results.json', 'w') as f:
        json.dump(output, f, indent=2, ensure_ascii=False)
    
    print("\nâœ… ç»“æœå·²ä¿å­˜åˆ°: hybrid_recognition_results.json")


if __name__ == "__main__":
    demo()
